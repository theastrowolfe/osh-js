{
    "docs": [
        {
            "location": "/",
            "text": "OpenSensorHub Web Client Toolkit Documentation\n\n\nOpenSensorHub Web Client toolkit allows you to visualize data from OSH. It provides the necessary tools to build your own web application for monitoring your sensors.\nIt is pure javascript framework and does not require third party libraries. A set of external libraries is also available to easily build some part of your views such as\nLeaflet, OpenLayer, Cesium, NVD3 etc..\n\n\nIt's an event based architecture suitable for real-time or playback. It allows one to make temporal synchronization or multiple data stream. It provides a styling overlay using \nconfigurable stylers as well as an advanced support for video (H264/MJPEG). It has been designed to integrate any map engines such as Lealfet, OpenLayer or Cesium.\n\n\nMoreover, it offers support for SOS \n SPS services, discovery function, uses the HTTP or WebSocket API.\nSeveral modules already exist to allow one to setup quickly an application such as Orientation, Chart, Video, Map etc..\n\n\nPlease report all problems related to the SensorHub software including documentation errors via the \nGitHub Issue Tracker\n \nof the \nosh-js\n repository.",
            "title": "Introduction"
        },
        {
            "location": "/#opensensorhub-web-client-toolkit-documentation",
            "text": "OpenSensorHub Web Client toolkit allows you to visualize data from OSH. It provides the necessary tools to build your own web application for monitoring your sensors.\nIt is pure javascript framework and does not require third party libraries. A set of external libraries is also available to easily build some part of your views such as\nLeaflet, OpenLayer, Cesium, NVD3 etc..  It's an event based architecture suitable for real-time or playback. It allows one to make temporal synchronization or multiple data stream. It provides a styling overlay using \nconfigurable stylers as well as an advanced support for video (H264/MJPEG). It has been designed to integrate any map engines such as Lealfet, OpenLayer or Cesium.  Moreover, it offers support for SOS   SPS services, discovery function, uses the HTTP or WebSocket API.\nSeveral modules already exist to allow one to setup quickly an application such as Orientation, Chart, Video, Map etc..  Please report all problems related to the SensorHub software including documentation errors via the  GitHub Issue Tracker  \nof the  osh-js  repository.",
            "title": "OpenSensorHub Web Client Toolkit Documentation"
        },
        {
            "location": "/download/",
            "text": "How To Download\n\n\nReleases\n\n\nBinary and Source distributions archives can be downloaded directly from the \nReleases Section\n of our GitHub account.\n\n\nThe release contains a vendor directory (needed for some pre-coded views), the minified osh-js library and its corresponding stylesheet.\nYou can use both the all-in-one vendor minified script(vendor.js \n vendor.css) or the separate ones. \n\n\nSee the \nInstall Section\n for instructions on how to set it up on your device.",
            "title": "Download"
        },
        {
            "location": "/download/#how-to-download",
            "text": "",
            "title": "How To Download"
        },
        {
            "location": "/download/#releases",
            "text": "Binary and Source distributions archives can be downloaded directly from the  Releases Section  of our GitHub account.  The release contains a vendor directory (needed for some pre-coded views), the minified osh-js library and its corresponding stylesheet.\nYou can use both the all-in-one vendor minified script(vendor.js   vendor.css) or the separate ones.   See the  Install Section  for instructions on how to set it up on your device.",
            "title": "Releases"
        },
        {
            "location": "/install/",
            "text": "How To Use\n\n\nAll you need to use the toolkit is to include the vendor dist file (the all-in-one or the separate ones) and the minified osh javascript and stylesheet:\n\n\n!-- VENDOR --\n\n\nlink rel=\nstylesheet\n href=\nvendor/vendor.min.css\n/\n\n\nscript type=\ntext/javascript\n src=\nvendor/all-in-one/vendor.min.js\n/script\n\n\n\n!-- OSH Toolkit --\n\n\nlink rel=\nstylesheet\n href=\ncss/osh.min.css\n/\n\n\nscript src=\njs/osh.min.js\n/script\n\n\n\n\n\nDon't forget to include the {css,images,js} directories.",
            "title": "How to use"
        },
        {
            "location": "/install/#how-to-use",
            "text": "All you need to use the toolkit is to include the vendor dist file (the all-in-one or the separate ones) and the minified osh javascript and stylesheet:  !-- VENDOR --  link rel= stylesheet  href= vendor/vendor.min.css /  script type= text/javascript  src= vendor/all-in-one/vendor.min.js /script  !-- OSH Toolkit --  link rel= stylesheet  href= css/osh.min.css /  script src= js/osh.min.js /script   Don't forget to include the {css,images,js} directories.",
            "title": "How To Use"
        },
        {
            "location": "/dev/dev-guide/",
            "text": "Developer's Guide\n\n\nThis guide is meant to help you setup a development environment so that you can extend OpenSensorHub (OSH for short) \nwith your own datasources, views or modules.\n\n\nDon't forget to send us a Pull Request if you want to contribute to this project with your work. Other users may be interested in your modules and bug fixes!\n\n\nOf course, contributing new modules to the community is optional as our license does not prevent proprietary and commercial derived work. However, keep in mind that \nif you modify the source files we provide, you must make it available publicly in source form\n. \n\n\nThis page provides instructions for three possible options, depending on your level of involvement:\n\n\n\n\n\n\nExploring the code online\n\n\n\n\n\n\nGetting the code\n using Git\n\n\n\n\n\n\nBuild using NPM, bower and Gulp\n\n\n\n\n\n\nContributing\n new features and bug fixes to the project\n\n\n\n\n\n\nExploring the Code\n\n\nIf you just want to explore the code, you can browse the source online directly on \n\nGithub OSH Toolkit\n. Alternatively, you can download it to your computer using the \nDownload ZIP\n link on each GitHub repository or using the \ngit\n program (see next section).\nIt is part of the global \nOSH\n project.\n\n\nGetting the code\n\n\nThe \ngit\n command is used to download the code from the Github repositories. For example, you can download the code for the core modules using the following command:\n\n\n$ git clone --recursive https://github.com/opensensorhub/osh-js.git\n\n\n\n\nTechnologies \n frameworks\n\n\nThe Toolkit is pure Javascript and uses CSS3 for styling. Some external extra libraries add extra functionnalities:\n\n\n\n\n\n\nCesium: pure js 3D globe\n\n\n\n\n\n\nx2js: convert XML into JSON\n\n\n\n\n\n\nnouislider: time slider bar\n\n\n\n\n\n\nNVD3: re-usable chart for d3.js\n\n\n\n\n\n\nOpenLayer\n\n\n\n\n\n\nLeaflet\n\n\n\n\n\n\nCustom javascript tree\n\n\n\n\n\n\nFfmpeg: portage of the Ffmpeg C++ library into JS (emscripten) to decode H264 frames\n\n\n\n\n\n\nBuilding from Source\n\n\nPre-requisites\n\n\nThe building uses NPM, Bower and Gulp. Be sure you have installed them before continuing.\n\n\n\n\n\n\nNPM: This is a package manager for Javascript \nGet NPM\n\n\n\n\n\n\nBower: A package manager for the web \nGet Bower\n \n\n\n\n\n\n\nGulp: It's a build system allowing to automate tasks \nGet Gulp\n\n\n\n\n\n\nJsDoc: Tool to build documentation \nGet JsDoc\n\n\n\n\n\n\nBuild\n\n\nInstall plugins dependencies using NPM:\n\nToolkit $ npm install\n\n\nInstall vendor dependencies using bower:\n\nToolkit $ bower install\n\n\nDisplay Gulp help:\n\n\nTookit $ gulp help\nUsage\n  gulp [TASK] [OPTIONS...]\n\nAvailable tasks\n  build           build a distributable osh-js instance \n   --cesium       An open-source JavaScript library for world-class 3D globes and maps: https://cesiumjs.org/\n\n   --ffmpeg       Include FFMPEG library. This library provides FFmpeg builds ported to JavaScript using Emscripten project. Builds are optimized for in-browser use: minimal size for \nfaster loading, asm.js, performance tunings, etc. This is a fork from Kagami/ffmpeg.js: https://github.com/sensiasoft/ffmpeg.js\n\n   --x2js       Include x2js library. This is used to map XML data into JSON object\n\n   --leaflet      An open-source JavaScript library for mobile-friendly interactive maps: http://leafletjs.com/\n\n   --nouislider   This library is responsible for displaying the RangeSlider bar.It is lightweight JavaScript range slider, originally developed to be a jQuery UI alternative: \nhttps://github.com/leongersen/noUiSlider\n\n   --nvd3         Include NVD3 library: http://nvd3.org/\n\n   --ol3          OpenLayer 3 makes it easy to put a dynamic map in any web page. It can display map tiles, vector data and markers loaded from any source: https://openlayers.org/\n\n   --tree         This library is responsible for displaying the Entity Tree View. It is a pure Javascript TreeView Component: https://github.com/rafaelthca/aimaraJS\n\n  clean           Clean the dist directory\n\n  help            Display this help text.\n\n\n\n\nBuild a full version using gulp:\n\nToolkit $ gulp build\n\n\nAs described in the gulp help command, you can also include some libraries:\n\n\nToolkit $ gulp build --ffmpeg --leaflet\n\n\nA dist directory will be created containing the new files, for this example:\n\n\ndist/\n\u251c\u2500\u2500 css\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 font-awesome-4.6.3\n.   .\n.   .    ...\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 osh-debug.css\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 osh.min.css\n\u251c\u2500\u2500 images\n.   .\n.   .   ...\n\u251c\u2500\u2500 js\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 osh-debug.js\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 osh.min.js\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 workers\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 ffmpeg-h264.js\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 osh-UI-FFMPEGViewWorker.js\n\u2514\u2500\u2500 vendor\n    \u251c\u2500\u2500 fullscreen@2x.png\n    \u251c\u2500\u2500 fullscreen.png\n    \u251c\u2500\u2500 images\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 layers-2x.png\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 layers.png\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 marker-icon-2x.png\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 marker-icon.png\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 marker-shadow.png\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 spritesheet-2x.png\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 spritesheet.png\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 spritesheet.svg\n    \u251c\u2500\u2500 vendor-debug.css\n    \u251c\u2500\u2500 vendor-debug.js\n    \u251c\u2500\u2500 vendor.min.css\n    \u2514\u2500\u2500 vendor.min.js\n\n\n\n\nThe result is a set of files that you can load to use the Toolkit. An \nosh-debug\n and \nosh.min\" files are produced to get a minified or debug version of the toolkit as well as the \nstylesheet files.\nALl the vendor files are produced into the \ndist/vendor\n directory. Like the \nosh* files, there are a debug and minified version. All the directories located into the vendor folder \nare relative to the javascript/stylesheet files. Keep this structure as it is produced to get a working version of the vendor file.\n\n\nThe \njs\n directory contains:\n\n\n\n\nosh-debug.js: the debug version of the Toolkit\n\n\nosh.min.js: the minified version of the Toolkit\n\n\nworkers directory: the workers directory. To use workers, you have to set the workers directory structure as: \"BASE_PROJECT_ROOT\"/js/workers. Otherwise the workers could not be used.",
            "title": "Developer's Guide"
        },
        {
            "location": "/dev/dev-guide/#developers-guide",
            "text": "This guide is meant to help you setup a development environment so that you can extend OpenSensorHub (OSH for short) \nwith your own datasources, views or modules.  Don't forget to send us a Pull Request if you want to contribute to this project with your work. Other users may be interested in your modules and bug fixes!  Of course, contributing new modules to the community is optional as our license does not prevent proprietary and commercial derived work. However, keep in mind that  if you modify the source files we provide, you must make it available publicly in source form .   This page provides instructions for three possible options, depending on your level of involvement:    Exploring the code online    Getting the code  using Git    Build using NPM, bower and Gulp    Contributing  new features and bug fixes to the project",
            "title": "Developer's Guide"
        },
        {
            "location": "/dev/dev-guide/#exploring-the-code",
            "text": "If you just want to explore the code, you can browse the source online directly on  Github OSH Toolkit . Alternatively, you can download it to your computer using the  Download ZIP  link on each GitHub repository or using the  git  program (see next section).\nIt is part of the global  OSH  project.",
            "title": "Exploring the Code"
        },
        {
            "location": "/dev/dev-guide/#getting-the-code",
            "text": "The  git  command is used to download the code from the Github repositories. For example, you can download the code for the core modules using the following command:  $ git clone --recursive https://github.com/opensensorhub/osh-js.git",
            "title": "Getting the code"
        },
        {
            "location": "/dev/dev-guide/#technologies-frameworks",
            "text": "The Toolkit is pure Javascript and uses CSS3 for styling. Some external extra libraries add extra functionnalities:    Cesium: pure js 3D globe    x2js: convert XML into JSON    nouislider: time slider bar    NVD3: re-usable chart for d3.js    OpenLayer    Leaflet    Custom javascript tree    Ffmpeg: portage of the Ffmpeg C++ library into JS (emscripten) to decode H264 frames",
            "title": "Technologies &amp; frameworks"
        },
        {
            "location": "/dev/dev-guide/#building-from-source",
            "text": "",
            "title": "Building from Source"
        },
        {
            "location": "/dev/dev-guide/#pre-requisites",
            "text": "The building uses NPM, Bower and Gulp. Be sure you have installed them before continuing.    NPM: This is a package manager for Javascript  Get NPM    Bower: A package manager for the web  Get Bower      Gulp: It's a build system allowing to automate tasks  Get Gulp    JsDoc: Tool to build documentation  Get JsDoc",
            "title": "Pre-requisites"
        },
        {
            "location": "/dev/dev-guide/#build",
            "text": "Install plugins dependencies using NPM: Toolkit $ npm install  Install vendor dependencies using bower: Toolkit $ bower install  Display Gulp help:  Tookit $ gulp help\nUsage\n  gulp [TASK] [OPTIONS...]\n\nAvailable tasks\n  build           build a distributable osh-js instance \n   --cesium       An open-source JavaScript library for world-class 3D globes and maps: https://cesiumjs.org/\n\n   --ffmpeg       Include FFMPEG library. This library provides FFmpeg builds ported to JavaScript using Emscripten project. Builds are optimized for in-browser use: minimal size for \nfaster loading, asm.js, performance tunings, etc. This is a fork from Kagami/ffmpeg.js: https://github.com/sensiasoft/ffmpeg.js\n\n   --x2js       Include x2js library. This is used to map XML data into JSON object\n\n   --leaflet      An open-source JavaScript library for mobile-friendly interactive maps: http://leafletjs.com/\n\n   --nouislider   This library is responsible for displaying the RangeSlider bar.It is lightweight JavaScript range slider, originally developed to be a jQuery UI alternative: \nhttps://github.com/leongersen/noUiSlider\n\n   --nvd3         Include NVD3 library: http://nvd3.org/\n\n   --ol3          OpenLayer 3 makes it easy to put a dynamic map in any web page. It can display map tiles, vector data and markers loaded from any source: https://openlayers.org/\n\n   --tree         This library is responsible for displaying the Entity Tree View. It is a pure Javascript TreeView Component: https://github.com/rafaelthca/aimaraJS\n\n  clean           Clean the dist directory\n\n  help            Display this help text.  Build a full version using gulp: Toolkit $ gulp build  As described in the gulp help command, you can also include some libraries:  Toolkit $ gulp build --ffmpeg --leaflet  A dist directory will be created containing the new files, for this example:  dist/\n\u251c\u2500\u2500 css\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 font-awesome-4.6.3\n.   .\n.   .    ...\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 osh-debug.css\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 osh.min.css\n\u251c\u2500\u2500 images\n.   .\n.   .   ...\n\u251c\u2500\u2500 js\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 osh-debug.js\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 osh.min.js\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 workers\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 ffmpeg-h264.js\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 osh-UI-FFMPEGViewWorker.js\n\u2514\u2500\u2500 vendor\n    \u251c\u2500\u2500 fullscreen@2x.png\n    \u251c\u2500\u2500 fullscreen.png\n    \u251c\u2500\u2500 images\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 layers-2x.png\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 layers.png\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 marker-icon-2x.png\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 marker-icon.png\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 marker-shadow.png\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 spritesheet-2x.png\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 spritesheet.png\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 spritesheet.svg\n    \u251c\u2500\u2500 vendor-debug.css\n    \u251c\u2500\u2500 vendor-debug.js\n    \u251c\u2500\u2500 vendor.min.css\n    \u2514\u2500\u2500 vendor.min.js  The result is a set of files that you can load to use the Toolkit. An  osh-debug  and  osh.min\" files are produced to get a minified or debug version of the toolkit as well as the \nstylesheet files.\nALl the vendor files are produced into the  dist/vendor  directory. Like the  osh* files, there are a debug and minified version. All the directories located into the vendor folder \nare relative to the javascript/stylesheet files. Keep this structure as it is produced to get a working version of the vendor file.  The  js  directory contains:   osh-debug.js: the debug version of the Toolkit  osh.min.js: the minified version of the Toolkit  workers directory: the workers directory. To use workers, you have to set the workers directory structure as: \"BASE_PROJECT_ROOT\"/js/workers. Otherwise the workers could not be used.",
            "title": "Build"
        },
        {
            "location": "/dev/architecture/",
            "text": "Architecture\n\n\nGlobal architecture\n\n\nThe toolkit can be split into five parts:\n\n\n1) The Event manager: a global bus to communicate between components\n\n\n2) The data sources (data providers): they are connected to the server to get the data. They are represented by many types such as binary, text etc.\n\n\n3) The buffer: every data got from the data sources are handled by the buffer. It allows data synchronization and buffering\n\n\n4) The stylers: map the json data to graphic properties\n\n\n5) The views: rendering divs and general rendering options\n\n\n\n\nEvent Manager\n\n\n\n\nIt acts as an Event bus, it connects the data sources, views and buffer.\n\n\nIt contains Event enumeration such as:\n\n\n\n\n\n\nDATA-\nid\n: gets the specific data after the buffering process\n\n\n\n\n\n\nCONNECT_DATASOURCE-\nid\n: sends an event to connect a specific data source\n\n\n\n\n\n\nPTZ_SEND_REQUEST-\nid\n: handles request to send (such as SPS)\n\n\n\n\n\n\n...\n\n\n\n\n\n\nIf the event concerned a data, it is often postfix with the id of the concerned data sources.\n\n\nData connector\n\n\nThe Toolkit uses the data connector Abstract class to get/send the data. This is the link between the client and\nthe OSH server. It does not contain any logic and gets only the data through two ways:\n\n\n\n\n\n\nWebSocket API: connects to the server using the WebSocket Javascript API. The connector is encapsulated into\n a WebWorker if it is supported by the browser\n\n\n\n\n\n\nHttp API: connects to the server using the XmlHttpRequest API\n\n\n\n\n\n\n\n\nData Receiver \n Data Sender\n\n\nA Data Receiver/Sender is used to parse the data got from the SOS server. The data contains a timestamp \nand the raw data. The timestamp has to be separated to be used into the buffer to process synchronization.\nIt also builds the final url given:\n\n\n\n\n\n\nprotocol: specify the protocol (data connector) to use\n\n\n\n\n\n\nendpoint: the sos endpoint url\n\n\n\n\n\n\noffering: the specific offering id\n\n\n\n\n\n\nobservedProperty: the specific observed property\n\n\n\n\n\n\nstart time: the begin position\n\n\n\n\n\n\nend time: the end position\n\n\n\n\n\n\nreplay speed: because the Toolkit allows synchronization, you can use real-time data as well as playback data. \nThe replay speed allows one to accelerate the time for the playback one.\n\n\n\n\n\n\n(See technical details)[#technical-data-receiver]\n\n\n\n\n\n\nData Receiver - SOS\n\n\nBy default, the data receiver uses the WebSocket API. The WebSocket is used inside a non-blocking Web Worker.\nUsing WebWorkers allows the Application to get multiple data into different threads and does not block the \nmain Thread (the rendering divs).\nAs part of the data receiver package, some have already been implemented:\n\n\n \n\n\nA generic data receiver has been implemented to handle textual data got from SOS server \nSee OSH.DataReceiver.JSON\n.\nTo implement your own data receiver, you only need to extend \nOSH.DataReceiver.DataSource\n and implement\nthe \nparseData()\n as well as the \nparseTimeStamp()\n which separate the timestamp and the raw data from the SOS stream.\n\n\nData Sender - SPS\n\n\nThe data sender allows one to send requests to the server. Usually it is used to send SPS requests (for example in case of PTZ tasking).\n\n\nLike the Data Receiver, an abstract class has to be inherited and provides necessary functions to simplify the request building chain. \n\n\n \n\n\nBuffer\n\n\nEvery data got from the SOS stream are sent to the buffer (using the EventManager). It can synchronize the data and handle playback/real-time. \nOnce the data are processed by the buffer, they are sent back to the bus through the EventManager to be processed by the other components (Views, Stylers etc..).\nThe buffer can be used as a standalone component as well as into the \nOSH.DataReceiver.DataReceiverController\n.\n\n\nThe DataReceiver is a helper class to wrap and abstract some logic. It uses a single buffer instance and calls back the result to the EventManager.\n\n\n \n\n\nData receiver/sender(R/S) VS entity\n\n\nAn entity is a set of data R/S. It makes the link between several Data R/S defined by different views:\n\n\n\n\n\n\none click onto a view representing a data can highlight another view representing another data contained in the same entity\n\n\n\n\n\n\nit allows firing group events such as show, hide, highlight\n\n\n\n\n\n\nThe views\n\n\nA view represents one or more data. It gets the data from the EventManager. A view is defined by one or more ViewItems. A viewItem is composed of:\n\n\n\n\n\n\na styler\n\n\n\n\n\n\na contextual menu\n\n\n\n\n\n\nan array of entity ids\n\n\n\n\n\n\nan array of data receivers\n\n\n\n\n\n\nSome views don't need view items such as:\n\n\n\n\n\n\nRange slider\n\n\n\n\n\n\nDiscovery\n\n\n\n\n\n\nDialog\n\n\n\n\n\n\nTheir kind of views don't represent the data, they do not have direct link with a data receiver.\n\n\n \n\n\nStylers\n\n\nThe stylers allow one to style the data. They are generic and use functions to filter the input data. Once the data has been processed by the styler, the result is sent back to the view \nand displayed. Many kinds of stylers are available:\n\n\n\n\n\n\ntext\n\n\n\n\n\n\nicon \n\n\n\n\n\n\nline\n\n\n\n\n\n\nmap point\n\n\n\n\n\n\n...\n\n\n\n\n\n\nThey are not mandatory.\n\n\n Context menus\n\n\nThey are sets of abstract classes used to represent a menu. They can have different representations such as circular, stack etc. They are built from \nmenuItems\n owning:\n\n\n\n\n\n\nname: the name of the menu\n\n\n\n\n\n\nviewId: a link to the view\n\n\n\n\n\n\ncss classes: to style the menu\n\n\n\n\n\n\nA \nmenuItem\n makes the link between the view and the context menu (through event messages).",
            "title": "Architecture"
        },
        {
            "location": "/dev/architecture/#architecture",
            "text": "",
            "title": "Architecture"
        },
        {
            "location": "/dev/architecture/#global-architecture",
            "text": "The toolkit can be split into five parts:  1) The Event manager: a global bus to communicate between components  2) The data sources (data providers): they are connected to the server to get the data. They are represented by many types such as binary, text etc.  3) The buffer: every data got from the data sources are handled by the buffer. It allows data synchronization and buffering  4) The stylers: map the json data to graphic properties  5) The views: rendering divs and general rendering options",
            "title": "Global architecture"
        },
        {
            "location": "/dev/architecture/#event-manager",
            "text": "It acts as an Event bus, it connects the data sources, views and buffer.  It contains Event enumeration such as:    DATA- id : gets the specific data after the buffering process    CONNECT_DATASOURCE- id : sends an event to connect a specific data source    PTZ_SEND_REQUEST- id : handles request to send (such as SPS)    ...    If the event concerned a data, it is often postfix with the id of the concerned data sources.",
            "title": "Event Manager"
        },
        {
            "location": "/dev/architecture/#data-connector",
            "text": "The Toolkit uses the data connector Abstract class to get/send the data. This is the link between the client and\nthe OSH server. It does not contain any logic and gets only the data through two ways:    WebSocket API: connects to the server using the WebSocket Javascript API. The connector is encapsulated into\n a WebWorker if it is supported by the browser    Http API: connects to the server using the XmlHttpRequest API",
            "title": "Data connector"
        },
        {
            "location": "/dev/architecture/#data-receiver-data-sender",
            "text": "A Data Receiver/Sender is used to parse the data got from the SOS server. The data contains a timestamp \nand the raw data. The timestamp has to be separated to be used into the buffer to process synchronization.\nIt also builds the final url given:    protocol: specify the protocol (data connector) to use    endpoint: the sos endpoint url    offering: the specific offering id    observedProperty: the specific observed property    start time: the begin position    end time: the end position    replay speed: because the Toolkit allows synchronization, you can use real-time data as well as playback data. \nThe replay speed allows one to accelerate the time for the playback one.    (See technical details)[#technical-data-receiver]",
            "title": "Data Receiver &amp; Data Sender"
        },
        {
            "location": "/dev/architecture/#data-receiver-sos",
            "text": "By default, the data receiver uses the WebSocket API. The WebSocket is used inside a non-blocking Web Worker.\nUsing WebWorkers allows the Application to get multiple data into different threads and does not block the \nmain Thread (the rendering divs).\nAs part of the data receiver package, some have already been implemented:     A generic data receiver has been implemented to handle textual data got from SOS server  See OSH.DataReceiver.JSON .\nTo implement your own data receiver, you only need to extend  OSH.DataReceiver.DataSource  and implement\nthe  parseData()  as well as the  parseTimeStamp()  which separate the timestamp and the raw data from the SOS stream.",
            "title": "Data Receiver - SOS"
        },
        {
            "location": "/dev/architecture/#data-sender-sps",
            "text": "The data sender allows one to send requests to the server. Usually it is used to send SPS requests (for example in case of PTZ tasking).  Like the Data Receiver, an abstract class has to be inherited and provides necessary functions to simplify the request building chain.",
            "title": "Data Sender - SPS"
        },
        {
            "location": "/dev/architecture/#buffer",
            "text": "Every data got from the SOS stream are sent to the buffer (using the EventManager). It can synchronize the data and handle playback/real-time. \nOnce the data are processed by the buffer, they are sent back to the bus through the EventManager to be processed by the other components (Views, Stylers etc..).\nThe buffer can be used as a standalone component as well as into the  OSH.DataReceiver.DataReceiverController .  The DataReceiver is a helper class to wrap and abstract some logic. It uses a single buffer instance and calls back the result to the EventManager.",
            "title": "Buffer"
        },
        {
            "location": "/dev/architecture/#data-receiversenderrs-vs-entity",
            "text": "An entity is a set of data R/S. It makes the link between several Data R/S defined by different views:    one click onto a view representing a data can highlight another view representing another data contained in the same entity    it allows firing group events such as show, hide, highlight",
            "title": "Data receiver/sender(R/S) VS entity"
        },
        {
            "location": "/dev/architecture/#the-views",
            "text": "A view represents one or more data. It gets the data from the EventManager. A view is defined by one or more ViewItems. A viewItem is composed of:    a styler    a contextual menu    an array of entity ids    an array of data receivers    Some views don't need view items such as:    Range slider    Discovery    Dialog    Their kind of views don't represent the data, they do not have direct link with a data receiver.",
            "title": "The views"
        },
        {
            "location": "/dev/architecture/#stylers",
            "text": "The stylers allow one to style the data. They are generic and use functions to filter the input data. Once the data has been processed by the styler, the result is sent back to the view \nand displayed. Many kinds of stylers are available:    text    icon     line    map point    ...    They are not mandatory.",
            "title": "Stylers"
        },
        {
            "location": "/dev/technical/",
            "text": "Technical\n\n\nEventManager\n\n\nThe EventManager is handled by the \nOSH.EventManager\n class.\nIt is used through the entire Toolkit. For example, the data are sent from the data receiver to the buffer using the callback function, and the\nbuffer forwards the events after processing them into the EventManager.\n\n\nThere are then many ways to use the OSH.EventManager. As it is used through the entire Toolkit, you can send/receive on events\ndirectly by using the OSH.EventManager class.\n\n\nMost of the events are defined by \nOSH.EventManager.EVENT\n :\n\n\nOSH.EventManager.EVENT = {\n    DATA : \ndata\n,\n    SYNC_DATA : \nsyncData\n,\n    SELECT_VIEW : \nselectView\n,\n    CONTEXT_MENU : \ncontextMenu\n,\n    SHOW_VIEW : \nshowView\n,\n    CONNECT_DATASOURCE : \nconnectDataSource\n,\n    DISCONNECT_DATASOURCE : \ndisconnectDataSource\n,\n    DATASOURCE_UPDATE_TIME: \nupdateDataSourceTime\n,\n    CURRENT_MASTER_TIME : \ncurrentMasterTime\n,\n    UAV_TAKEOFF : \nuav:takeoff\n,\n    UAV_GOTO: \nuav:goto\n,\n    UAV_LOOKAT : \nuav:lookat\n,\n    UAV_LAND: \nuav:land\n,\n    UAV_ORBIT: \nuav:orbit\n,\n    LOADING_START: \nloading:start\n,\n    LOADING_STOP: \nloading:stop\n,\n    ADD_VIEW_ITEM: \naddViewItem\n,\n    RESIZE:\nresize\n,\n    PTZ_SEND_REQUEST:\nptzSendRequest\n\n};\n\n\n\n\nIn some situations, the events are postfixed by an id. For example, in the case of sending data from data receivers,\nthe data is sent as a JSON object with an event \nDATA-\nid\n. \n\n\nDATA\n\n\nOnce the data received and splitted by the data source, they are sent to the buffer as:\n\n\ndataSource.onData = function (data) {\n      this.buffer.push({dataSourceId: dataSource.getId(), data: data});\n\n}.bind(this);\n\n\n\n\nWe don't use message passing here to not overload Event manager. Then the buffer processes the data and sent them back to EventManager:\n\n\n...\nOSH.EventManager.fire(OSH.EventManager.EVENT.DATA+\n-\n+dataSourceId, {data : data});\n...\n\n\n\n\nEvery data is postfixed with its datasource id. This is to optmize the observation process.\n\n\nIf one is interested in getting the data, it can observe the corresponding data by listening to the EventManager:\n\n\n...\nOSH.EventManager.observe(OSH.EventManager.EVENT.DATA + \n-\n + \ndatasourceId\n, function (event) {\n...\n}\n\n\n\n\nCURRENT_MASTER_TIME\n\n\nThe \nCURRENT_MASTER_TIME\n allows to send the current timestamp being processed. This is sent by the buffer after processing (at the same time as the DATA event) and it is observed\nby the \nOSH.UI.RangeSlider\n view to move the slider cursor.\n\n\nSELECT_VIEW\n\n\nThe \nSELECT_VIEW\n event is sent to select a view. It contains a data source id array and an entity id:\n\n\n OSH.EventManager.fire(OSH.EventManager.EVENT.SELECT_VIEW,{\n    dataSourcesIds: [...],\n    entityId: [...],                    \n});\n\n\n\n\nEvery implemented view observes this event and apply the \ncss selected\n style when the data source ids are matching. For example, if you want to select a particular view, \nyou have to send this event with the data source ids concerned.\n\n\nCONTEXT_MENU\n\n\nThe Toolkit offers the ability to create and display different types of menus. See the \nContext menus\n. The event\nmanager provides the \nEVENT.CONTEXT_MENU\n event to send/receive messages.\nThe event is postfixed with the \ncontextMenuId\n like:\n\n\nOSH.EventManager.fire(OSH.EventManager.EVENT.CONTEXT_MENU+\n-\n+\ncontextMenuId\n,{\n...\n});\n\n\n\n\nand it is observed by the corresponding \nOSH.ContextMenu\n class:\n\n\nOSH.EventManager.observe(OSH.EventManager.EVENT.CONTEXT_MENU+\n-\n+this.id,function(event) {\n...\n}\n\n\n\n\nThe supported actions are:\n\n\n\n\n\n\nshow: show the context menu\n\n\n\n\n\n\nhide: hide the context menu\n\n\n\n\n\n\nOSH.EventManager.fire(OSH.EventManager.EVENT.CONTEXT_MENU+\n-\n+\ncontextMenuId\n,{\n   ...  \n   action:\nshow\n // or hide\n});\n\n\n\n\nnote: this part should be improved in a future release\n\n\nThe viewItem has been designed to have a \ncontextMenuId\n property. See the tutorial for more details about creating a Context menu \nTutorial\n\n\nCONNECT_DATASOURCE/DISCONNECT_DATASOURCE\n\n\nThe current implementation allows to send Connect/disconnect event to disconnect a current running data source. It works only if your data sources have been attached to a \n\nOSH.DataReceiver.DataReceiverController\n.\n\n\nOSH.EventManager.fire(OSH.EventManager.EVENT.CONNECT_DATASOURCE, {dataSourcesId: \ndataSourceId to connect\n});\n\n\n\n\nOSH.EventManager.fire(OSH.EventManager.EVENT.DISCONNECT_DATASOURCE, {dataSourcesId: \ndataSourceId to disconnect\n});\n\n\n\n\nCURRENT_MASTER_TIME\n\n\nThis event is internally used to send event from the buffer to any component wanting get the current synchronized time. This is currenlty used by the \n\nOSH.UI.RangeSlider\n view.\n\n\nADD_VIEW_ITEM\n\n\nThere are two ways to add a view item to your view:\n\n\n\n\n\n\nas an array argument when you instantiate your class (See tutorials to have working examples)\n\n\n\n\n\n\nsend an event through the EventManager\n\n\n\n\n\n\nAdding a view item using the EventManager is quite simple and can be summarized as follows:\n\n\n...\nOSH.EventManager.fire(OSH.EventManager.EVENT.ADD_VIEW_ITEM,{viewItem:viewItem,viewId:viewId});\n...\n\n\n\n\nYou have to pass as a property of your freshly created viewItem and the viewId of the target view.\n\n\nIf you have created a new view, the abstract \nOSH.UI.View\n already observe this event.\n\n\nPTZ_SEND_REQUEST\n\n\nThis event allows one to send PTZ request to the \nOSH.DataSender.DataSink\n through the Event Manager. \nThe generic \nOSH.UI.PtzTaskingView\n already fire this event. If you want to use your own view:\n\n\n OSH.EventManager.fire(OSH.EventManager.EVENT.PTZ_SEND_REQUEST+\n-\n+\ndata sender id\n,{\n    cmdData : {rpan:\nrpan\n,rtilt:\nrtitl\n,rzoom:\nrzoom\n,preset:\npreset\n},\n    onSuccess:function(event){console.log(\nFailed to send request: \n+event);},\n    onError:function(event){console.log(\nRequest sent successfully: \n+event);}\n});\n\n\n\n\nThis is a fast way to communicate between your tasking view and the HttpConnector without taking into consideration internal processes.\n\n\nDataReceiver\n\n\nIn theory we have to create a different data receiver for every different streams we can use. OSH provides some generic re-usable data receiver which can be used with your existing data.\n\n\nDataReceiver JSON\n\n\nMost of the time, one can use the Generic DataReceiver described above to support text-encoded data streams. In cases where the data is not textual (such as binary, audio etc..), one may need to create a custom data receiver. The way to do this is described below.\n\n\nThe \nOSH.DataReceiver. JSON\n is a generic JSON datareceiver to parse JSON response. It connects to a JSON stream and \nparses the \n\"data\"\n and \n\"time\"\n properties.\n\n\nFor example, for the following GetResult request:\n\n\nhttp://sensiasoft.net:8181/sensorhub/sos?service=SOS\nversion=2.0\nrequest=GetResult\noffering=urn:mysos:offering03\nobservedProperty=http://sensorml.com/ont/swe/property/Weather\ntemporalFilter=phenomenonTime,now\nresponseFormat=application/json\n\n\n\n\nNote: the request contains \"\nresponseFormat=application/json\" to get a json response\n\n\nthe response would be:\n\n\n[\n  {\ntime\n: \n2017-05-23T08:37:30.893Z\n, \ntemperature\n: 22.919639646486733, \npressure\n: 1012.3488597792292, \nwindSpeed\n: 2.4516089709735143, \nwindDirection\n: 318.18582382006787}\n]\n\n\n\n\nAs described in the architecture part, the data receiver has to parse the time and the data. \n\n\nThe JSON one will also take the \"time\" property and create a new object containing the others fields \ntemperature\n, \npressure\n, \nwindSpeed\n, \nwindDirection\n.\nThe result after parsing is then:\n\n\n{\n  \ntimeStamp\n: \n2017-05-23T08:37:30.893Z\n,\n  \ndata\n: {\n    \ntemperature\n : 22.919639646486733,\n    \npressure\n: 1012.3488597792292, \n    \nwindSpeed\n: 2.4516089709735143, \n    \nwindDirection\n: 318.18582382006787\n  }\n}\n\n\n\n\nThe timeStamp property is then used to synchronize the data and the data part contains all the data values.\n\n\nRequests\n\n\nSOS (--x2js third party library)\n\n\nThe Toolkit provides tools to get information about your OSH server:\n\n\n\n\n\n\nGetCapabilities\n\n\n\n\n\n\nGetResultTemplate\n\n\n\n\n\n\nGetFeatureOfInterest\n\n\n\n\n\n\ndescribeSensor\n\n\n\n\n\n\nIn order to achieve the call, it will make request using HttpAjaxConnector and use \nx2js\n to parse XML response into JSON object.\nA wrapper class class has been implemented to simplify some part of the process:\n\n\nFirst, instantiate the wrapper class:\n\n\nvar server = new OSH.Server({\n    url:\nendpoint url\n,\n    sos: \nsos\n, // change this if different\n    sps: \nsps\n, // change this if different\n    baseUrl: \nsensorhub\n // change this if different\n});\n\n\n\n\nThen make the appropriate calls:\n\n\n// GetCapabilities\nserver.getCapabilities(function(jsonResp){\n    // do something\n},function(error) {\n    // do something\n});\n\n\n\n\n// GetFeatureOfInterest\nserver.getFeatureOfInterest(function(jsonResp){\n    // do something\n},function(error) {\n    // do something\n});\n\n\n\n\n// getResultTemplate\nserver.getResultTemplate(\noffering\n,\nobservedProperty\n,function(jsonResp){\n    // do something\n},function(error) {\n    // do something\n});\n\n\n\n\n// describeSensor\nserver.getDescribeSensor(\nprocedure\n,function(jsonResp){\n    // do something\n},function(error) {\n    // do something\n});\n\n\n\n\nA working example can be found at \nServer test\n\n\nSPS\n\n\nYou can either get stream from SOS service or make request to SPS service. An abstract class can be inherited. It handles a part of the logic such as\nthe http connector, send the request to the connector etc..\nSome implementation are available:\n\n\n\n\n\n\nOSH.DataSender.PtzTasking\n: generic ptz tasking using rpan,rtilt,rzoom command\n\n\n\n\n\n\nOSH.FoscamPtzTasking\n: send ptz request to Foscam camera\n\n\n\n\n\n\nOSH.DataSender.UavMapTasking\n: send command to drone\n\n\n\n\n\n\nTo task your hardware with PTZ command, you have either to use one the generic above class or create a new one. What you need is to inherit the \nOSH.DataSender.DataSink\n class \n and override the \ngetCommandData\n:\n\n\ngetCommandData: function (values) {...}\n\n\n\n\nThe \nOSH.UI.PtzTaskingView\n is a generic view allowing to task any kind of component.\nIt offers a control panel sending events observed by the \nOSH.DataSender.PtzTasking\n.\nThe \nonChange\n function of the PtzTaskingView can be overrided by another view to add more control on the command sent:\n\n\nonChange: function(rpan, rtilt, rzoom,preset) {\n    OSH.EventManager.fire(OSH.EventManager.EVENT.PTZ_SEND_REQUEST+\n-\n+this.dataSenderId,{\n        cmdData : {rpan:rpan,rtilt:rtilt,rzoom:rzoom,preset:preset},\n        onSuccess:function(event){console.log(\nFailed to send request: \n+event);},\n        onError:function(event){console.log(\nRequest sent successfully: \n+event);}\n    });\n}\n\n\n\n\nThe rpan, rtilt, rzoom and preset arguments are taking values from the click event. This should stay generic as much as possible and you should modify only the DataSink.\nThe \nOSH.DataSender.PtzTasking\n offers generic rtitl, rpan, rzoom and preset parameters. But in some cases, your camera driver will not match to these values, you can \ninherit from the \nOSH.DataSender.PtzTasking\n and override the getCommandData to handle and return the needed values to the abstract DataSink class.\n\n\nYou can take a look at the \nOSH.DataSender.FoscamPtzTasking\n source code to get a full working example since the Foscam OSH driver is waiting for \"Bottom, Top,Right, Left\" \nvalues instead of relative rpan/rzoom/rtilt values.\n\n\nDialog\n\n\nThe dialog window is an useful tool to display your view into floating dialog. The toolkit provides a simple and nice way to create/interact with your dialog:\n\n\nvar someDialog    = new OSH.UI.DialogView(\ndialog layout div id\n,{\n    css: \nyour css dialog\n,\n    name: \nDialogName\n,\n    show:false, // default show the dialog\n    draggable:true, // is the dialog is draggable?\n    dockable: false, // is the dialog is draggable?\n    closeable: true // is the dialog is closeable?,\n    connectionIds : dataSources // the array of attached data source\n    swapId: \ndiv id of the swap window\n\n});\n\n\n\n\n\n\n\n\ndialog layout div id\n: the div where the dialog will be attached. \n\n\n\n\n\n\ncss: the dialog has a default style which can be overrided, this css will be added to the existing dialog css\n\n\n\n\n\n\nshow: you can show/hide the dialog\n\n\n\n\n\n\ndraggable: you would want to fix the dialog position\n\n\n\n\n\n\ndockable: the dialog can be set to div, and can be move inside this div. If you undock the dialog, it will be attached directly to the document.body and not \nin the div anymore\n\n\n\n\n\n\ncloseable: display a button to close the dialog\n\n\n\n\n\n\nconnectionIds: since you can display a disconnect/connect button at the top of the dialog, this array is the link between the button and the data source concerned.\nWhen you click onto the disconnect button, the list of data source contains in this array will be disconnected (using DISCONNECT event of the Event Manager)\n\n\n\n\n\n\nswapId: you can swap the content of the dialog with another div (body for example)\n\n\n\n\n\n\nTo set a view into a dialog, you can specify the div id of the dialog as argument div view Id such as:\n\n\nvar someDialog    = new OSH.UI.DialogView(\ndialog layout div id\n,{\n    css: \nyour css dialog\n,\n    name: \nDialogName\n,\n    show:false, // default show the dialog\n    draggable:true, // is the dialog is draggable?\n    dockable: false, // is the dialog is draggable?\n    closeable: true // is the dialog is closeable?,\n    connectionIds : dataSources // the array of attached data source\n    swapId: \ndiv id of the swap window\n\n});\n\nvar someView = new OSH.UI.SomeView(someDialog.popContentDiv.id, [{...}],{...});\n\n\n\n\nThus the view will be automatically attached to the popContentDiv which is the dialog content. The best way to do that is to use the \nattachTo()\n function:\n\n\nvar someDialog    = new OSH.UI.DialogView(\ndialog layout div id\n,{\n    css: \nyour css dialog\n,\n    name: \nDialogName\n,\n    show:false, // default show the dialog\n    draggable:true, // is the dialog is draggable?\n    dockable: false, // is the dialog is draggable?\n    closeable: true // is the dialog is closeable?,\n    connectionIds : dataSources // the array of attached data source\n    swapId: \ndiv id of the swap window\n\n});\n\nvar someView = new OSH.UI.SomeView(\n, [{...}],{...}); // it's important here to let the div id empty !!!\nsomeView.attachTo(someDialog.popContentDiv.id);\n\n\n\n\nThis will automatically set the view into the dialog. Note that it is very important in that case to let the view divId empty because we don't want to attach it to something.\n\n\nMultiDialogView\n\n\nThe multi dialog view is an extension of the Dialog view. It allows one to append div to an existing dialog:\n\n\nvar multiDialog    =  new OSH.UI.MultiDialogView(\nsome container\n, {\n            draggable: true,\n            css: \ndialog-multidialog\n,\n            name: \nMulti dialog\n,\n            show:true,\n            dockable: false,\n            closeable: false,\n            connectionIds : [...]\n});\n\nvar someView = new OSH.UI.SomeView(\n, [{...}],{...}); // it's important here to let the div id empty !!!\nvar someView2 = new OSH.UI.SomeView(\n, [{...}],{...}); // it's important here to let the div id empty !!!\nvar someView3 = new OSH.UI.SomeView(\n, [{...}],{...}); // it's important here to let the div id empty !!!\n\n// attach the div view to the dialog\nsomeView.attachTo(multiDialog.popContentDiv.id);\n\nmultiDialog.appendView(someView2.divId);\nmultiDialog.appendView(someView3.divId);\n...\n\n\n\n\nThe someView 2 \n 3 will be appended to the dialog. See the \nMulti dialog + tasking example\n of the Showcase\n\n\nCesium (--cesium third party library)\n\n\nAs we have seen, one can directly built Cesium in osh vendor using Gulp. One specific one has to take care is the Cesium global property:\n\n\nwindow.CESIUM_BASE_URL = 'vendor/all-in-one';\n\n\n\n\nSince Cesium will try to load by default the Cesium library from the \njs\n folder, if this one is located into another folder, you have to specify the \nCESIUM_BASE_URL\n to get it work. \n\n\nFFMPEG (--ffmpeg third party library)\n\n\nThe FFMPEG library is a pure native Javascript library. It is used decode video frame in native javascript code.\n\n\n\"The original ffmpeg.js project provides FFmpeg builds ported to JavaScript using Emscripten project. Builds are optimized for in-browser use: minimal size for faster loading, asm.js, performance tunings, etc. Though they work in Node as well.\"\n\n\nSource\n\n\nBy using this library, one can decode H264 video frame in the browser without using any additional plugins.\nA wrapper has been implemented within the Toolkit and provides some useful functionnalities such as:\n\n\n\n\nDefine canvas size\n\n\nuse webworker\n\n\nincrease performance by using transferable objects\n\n\n\n\nOne can use the \nOSH.UI.FFMPEGView\n and build the library using --ffmpeg argument to Gulp such as:\n\n\n$ gulp build --ffmpeg\n\n\n\n\nThere are the default options of the View:\n\n\ndataSourceId: videoDataSource.id,\ncss: \nyour css\n,\ncssSelected: \nyou css after selecting the view\n,\nname: \nview name\n,\nuseWorker:\ntrue|false\n,\nuseWebWorkerTransferableData: \ntrue|false\n // this is because you can speed up the data transfert between main script and web worker\n                                            by using transferable data. Note that can cause problems if you data is attempted to use anywhere else.\n                                            See the not below for more details(*).\n\n\n\n\nOne can use the WebWorker which increases performance significantly since the decoding part is executed into a separated thread. It is very useful if several FFmpeg View are declared at the same time.\n\n\nAnother tip is to use the \nuseWebWorkerTransferableData\n which allows to use transferable object directly between the main thread and the WebWorker.\n\n\nThis property can cause trouble if you share the same data into different view because the pointer is transferred to the webworker and becomes then unavailable in the main thread.\n\n\nWithout transferable object:\n\n\nData --\n VIEW (data copied into)--\n WebWorker\n\n\nWith transferable object:\n\n\nData --\n VIEW (pointer transferred to)--\n WebWorker\n\n\nNot to copy the data increases the performance since transfert is much more faster.\n\n\nIf the data is only associated to one view, you should enable this parameter.\n\n\nExternal resources:\n \n\n\n\n\nhttps://developer.mozilla.org/en-US/docs/Web/API/Transferable\n\n\nhttps://developer.mozilla.org/en/docs/Web/API/Worker/postMessage\n\n\n\n\nIf the webworker property is enabled, the view will also spawn a WebWorker. Since the WebWorker has to load the FFmpeg.js library separately, the worker library is placed in the \nworkers\n\nfolder built by the \nGulp build\n command such as:\n\n\n... \n\n\u251c\u2500\u2500 js\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 osh.js\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 workers\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 ffmpeg-h264.js\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 osh-UI-FFMPEGViewWorker.js\n\n...       \n\n\n\n\nUsing the WebWorker is meaning you have to keep this structure to get it work. The \nworkers\n folder has to be right next to the \nosh.js\n file. The worker and the library are located at the same place.\nThe worker is loaded from the view as:\n\n\njs/workers/osh-UI-FFMPEGViewWorker.js",
            "title": "Technical"
        },
        {
            "location": "/dev/technical/#technical",
            "text": "",
            "title": "Technical"
        },
        {
            "location": "/dev/technical/#eventmanager",
            "text": "The EventManager is handled by the  OSH.EventManager  class.\nIt is used through the entire Toolkit. For example, the data are sent from the data receiver to the buffer using the callback function, and the\nbuffer forwards the events after processing them into the EventManager.  There are then many ways to use the OSH.EventManager. As it is used through the entire Toolkit, you can send/receive on events\ndirectly by using the OSH.EventManager class.  Most of the events are defined by  OSH.EventManager.EVENT  :  OSH.EventManager.EVENT = {\n    DATA :  data ,\n    SYNC_DATA :  syncData ,\n    SELECT_VIEW :  selectView ,\n    CONTEXT_MENU :  contextMenu ,\n    SHOW_VIEW :  showView ,\n    CONNECT_DATASOURCE :  connectDataSource ,\n    DISCONNECT_DATASOURCE :  disconnectDataSource ,\n    DATASOURCE_UPDATE_TIME:  updateDataSourceTime ,\n    CURRENT_MASTER_TIME :  currentMasterTime ,\n    UAV_TAKEOFF :  uav:takeoff ,\n    UAV_GOTO:  uav:goto ,\n    UAV_LOOKAT :  uav:lookat ,\n    UAV_LAND:  uav:land ,\n    UAV_ORBIT:  uav:orbit ,\n    LOADING_START:  loading:start ,\n    LOADING_STOP:  loading:stop ,\n    ADD_VIEW_ITEM:  addViewItem ,\n    RESIZE: resize ,\n    PTZ_SEND_REQUEST: ptzSendRequest \n};  In some situations, the events are postfixed by an id. For example, in the case of sending data from data receivers,\nthe data is sent as a JSON object with an event  DATA- id .",
            "title": "EventManager"
        },
        {
            "location": "/dev/technical/#data",
            "text": "Once the data received and splitted by the data source, they are sent to the buffer as:  dataSource.onData = function (data) {\n      this.buffer.push({dataSourceId: dataSource.getId(), data: data});\n\n}.bind(this);  We don't use message passing here to not overload Event manager. Then the buffer processes the data and sent them back to EventManager:  ...\nOSH.EventManager.fire(OSH.EventManager.EVENT.DATA+ - +dataSourceId, {data : data});\n...  Every data is postfixed with its datasource id. This is to optmize the observation process.  If one is interested in getting the data, it can observe the corresponding data by listening to the EventManager:  ...\nOSH.EventManager.observe(OSH.EventManager.EVENT.DATA +  -  +  datasourceId , function (event) {\n...\n}",
            "title": "DATA"
        },
        {
            "location": "/dev/technical/#current_master_time",
            "text": "The  CURRENT_MASTER_TIME  allows to send the current timestamp being processed. This is sent by the buffer after processing (at the same time as the DATA event) and it is observed\nby the  OSH.UI.RangeSlider  view to move the slider cursor.",
            "title": "CURRENT_MASTER_TIME"
        },
        {
            "location": "/dev/technical/#select_view",
            "text": "The  SELECT_VIEW  event is sent to select a view. It contains a data source id array and an entity id:   OSH.EventManager.fire(OSH.EventManager.EVENT.SELECT_VIEW,{\n    dataSourcesIds: [...],\n    entityId: [...],                    \n});  Every implemented view observes this event and apply the  css selected  style when the data source ids are matching. For example, if you want to select a particular view, \nyou have to send this event with the data source ids concerned.",
            "title": "SELECT_VIEW"
        },
        {
            "location": "/dev/technical/#context_menu",
            "text": "The Toolkit offers the ability to create and display different types of menus. See the  Context menus . The event\nmanager provides the  EVENT.CONTEXT_MENU  event to send/receive messages.\nThe event is postfixed with the  contextMenuId  like:  OSH.EventManager.fire(OSH.EventManager.EVENT.CONTEXT_MENU+ - + contextMenuId ,{\n...\n});  and it is observed by the corresponding  OSH.ContextMenu  class:  OSH.EventManager.observe(OSH.EventManager.EVENT.CONTEXT_MENU+ - +this.id,function(event) {\n...\n}  The supported actions are:    show: show the context menu    hide: hide the context menu    OSH.EventManager.fire(OSH.EventManager.EVENT.CONTEXT_MENU+ - + contextMenuId ,{\n   ...  \n   action: show  // or hide\n});  note: this part should be improved in a future release  The viewItem has been designed to have a  contextMenuId  property. See the tutorial for more details about creating a Context menu  Tutorial",
            "title": "CONTEXT_MENU"
        },
        {
            "location": "/dev/technical/#connect_datasourcedisconnect_datasource",
            "text": "The current implementation allows to send Connect/disconnect event to disconnect a current running data source. It works only if your data sources have been attached to a  OSH.DataReceiver.DataReceiverController .  OSH.EventManager.fire(OSH.EventManager.EVENT.CONNECT_DATASOURCE, {dataSourcesId:  dataSourceId to connect });  OSH.EventManager.fire(OSH.EventManager.EVENT.DISCONNECT_DATASOURCE, {dataSourcesId:  dataSourceId to disconnect });",
            "title": "CONNECT_DATASOURCE/DISCONNECT_DATASOURCE"
        },
        {
            "location": "/dev/technical/#current_master_time_1",
            "text": "This event is internally used to send event from the buffer to any component wanting get the current synchronized time. This is currenlty used by the  OSH.UI.RangeSlider  view.",
            "title": "CURRENT_MASTER_TIME"
        },
        {
            "location": "/dev/technical/#add_view_item",
            "text": "There are two ways to add a view item to your view:    as an array argument when you instantiate your class (See tutorials to have working examples)    send an event through the EventManager    Adding a view item using the EventManager is quite simple and can be summarized as follows:  ...\nOSH.EventManager.fire(OSH.EventManager.EVENT.ADD_VIEW_ITEM,{viewItem:viewItem,viewId:viewId});\n...  You have to pass as a property of your freshly created viewItem and the viewId of the target view.  If you have created a new view, the abstract  OSH.UI.View  already observe this event.",
            "title": "ADD_VIEW_ITEM"
        },
        {
            "location": "/dev/technical/#ptz_send_request",
            "text": "This event allows one to send PTZ request to the  OSH.DataSender.DataSink  through the Event Manager. \nThe generic  OSH.UI.PtzTaskingView  already fire this event. If you want to use your own view:   OSH.EventManager.fire(OSH.EventManager.EVENT.PTZ_SEND_REQUEST+ - + data sender id ,{\n    cmdData : {rpan: rpan ,rtilt: rtitl ,rzoom: rzoom ,preset: preset },\n    onSuccess:function(event){console.log( Failed to send request:  +event);},\n    onError:function(event){console.log( Request sent successfully:  +event);}\n});  This is a fast way to communicate between your tasking view and the HttpConnector without taking into consideration internal processes.",
            "title": "PTZ_SEND_REQUEST"
        },
        {
            "location": "/dev/technical/#datareceiver",
            "text": "In theory we have to create a different data receiver for every different streams we can use. OSH provides some generic re-usable data receiver which can be used with your existing data.",
            "title": "DataReceiver"
        },
        {
            "location": "/dev/technical/#datareceiver-json",
            "text": "Most of the time, one can use the Generic DataReceiver described above to support text-encoded data streams. In cases where the data is not textual (such as binary, audio etc..), one may need to create a custom data receiver. The way to do this is described below.  The  OSH.DataReceiver. JSON  is a generic JSON datareceiver to parse JSON response. It connects to a JSON stream and \nparses the  \"data\"  and  \"time\"  properties.  For example, for the following GetResult request:  http://sensiasoft.net:8181/sensorhub/sos?service=SOS version=2.0 request=GetResult offering=urn:mysos:offering03 observedProperty=http://sensorml.com/ont/swe/property/Weather temporalFilter=phenomenonTime,now responseFormat=application/json  Note: the request contains \" responseFormat=application/json\" to get a json response  the response would be:  [\n  { time :  2017-05-23T08:37:30.893Z ,  temperature : 22.919639646486733,  pressure : 1012.3488597792292,  windSpeed : 2.4516089709735143,  windDirection : 318.18582382006787}\n]  As described in the architecture part, the data receiver has to parse the time and the data.   The JSON one will also take the \"time\" property and create a new object containing the others fields  temperature ,  pressure ,  windSpeed ,  windDirection .\nThe result after parsing is then:  {\n   timeStamp :  2017-05-23T08:37:30.893Z ,\n   data : {\n     temperature  : 22.919639646486733,\n     pressure : 1012.3488597792292, \n     windSpeed : 2.4516089709735143, \n     windDirection : 318.18582382006787\n  }\n}  The timeStamp property is then used to synchronize the data and the data part contains all the data values.",
            "title": "DataReceiver JSON"
        },
        {
            "location": "/dev/technical/#requests",
            "text": "",
            "title": "Requests"
        },
        {
            "location": "/dev/technical/#sos-x2js-third-party-library",
            "text": "The Toolkit provides tools to get information about your OSH server:    GetCapabilities    GetResultTemplate    GetFeatureOfInterest    describeSensor    In order to achieve the call, it will make request using HttpAjaxConnector and use  x2js  to parse XML response into JSON object.\nA wrapper class class has been implemented to simplify some part of the process:  First, instantiate the wrapper class:  var server = new OSH.Server({\n    url: endpoint url ,\n    sos:  sos , // change this if different\n    sps:  sps , // change this if different\n    baseUrl:  sensorhub  // change this if different\n});  Then make the appropriate calls:  // GetCapabilities\nserver.getCapabilities(function(jsonResp){\n    // do something\n},function(error) {\n    // do something\n});  // GetFeatureOfInterest\nserver.getFeatureOfInterest(function(jsonResp){\n    // do something\n},function(error) {\n    // do something\n});  // getResultTemplate\nserver.getResultTemplate( offering , observedProperty ,function(jsonResp){\n    // do something\n},function(error) {\n    // do something\n});  // describeSensor\nserver.getDescribeSensor( procedure ,function(jsonResp){\n    // do something\n},function(error) {\n    // do something\n});  A working example can be found at  Server test",
            "title": "SOS (--x2js third party library)"
        },
        {
            "location": "/dev/technical/#sps",
            "text": "You can either get stream from SOS service or make request to SPS service. An abstract class can be inherited. It handles a part of the logic such as\nthe http connector, send the request to the connector etc..\nSome implementation are available:    OSH.DataSender.PtzTasking : generic ptz tasking using rpan,rtilt,rzoom command    OSH.FoscamPtzTasking : send ptz request to Foscam camera    OSH.DataSender.UavMapTasking : send command to drone    To task your hardware with PTZ command, you have either to use one the generic above class or create a new one. What you need is to inherit the  OSH.DataSender.DataSink  class \n and override the  getCommandData :  getCommandData: function (values) {...}  The  OSH.UI.PtzTaskingView  is a generic view allowing to task any kind of component.\nIt offers a control panel sending events observed by the  OSH.DataSender.PtzTasking .\nThe  onChange  function of the PtzTaskingView can be overrided by another view to add more control on the command sent:  onChange: function(rpan, rtilt, rzoom,preset) {\n    OSH.EventManager.fire(OSH.EventManager.EVENT.PTZ_SEND_REQUEST+ - +this.dataSenderId,{\n        cmdData : {rpan:rpan,rtilt:rtilt,rzoom:rzoom,preset:preset},\n        onSuccess:function(event){console.log( Failed to send request:  +event);},\n        onError:function(event){console.log( Request sent successfully:  +event);}\n    });\n}  The rpan, rtilt, rzoom and preset arguments are taking values from the click event. This should stay generic as much as possible and you should modify only the DataSink.\nThe  OSH.DataSender.PtzTasking  offers generic rtitl, rpan, rzoom and preset parameters. But in some cases, your camera driver will not match to these values, you can \ninherit from the  OSH.DataSender.PtzTasking  and override the getCommandData to handle and return the needed values to the abstract DataSink class.  You can take a look at the  OSH.DataSender.FoscamPtzTasking  source code to get a full working example since the Foscam OSH driver is waiting for \"Bottom, Top,Right, Left\" \nvalues instead of relative rpan/rzoom/rtilt values.",
            "title": "SPS"
        },
        {
            "location": "/dev/technical/#dialog",
            "text": "The dialog window is an useful tool to display your view into floating dialog. The toolkit provides a simple and nice way to create/interact with your dialog:  var someDialog    = new OSH.UI.DialogView( dialog layout div id ,{\n    css:  your css dialog ,\n    name:  DialogName ,\n    show:false, // default show the dialog\n    draggable:true, // is the dialog is draggable?\n    dockable: false, // is the dialog is draggable?\n    closeable: true // is the dialog is closeable?,\n    connectionIds : dataSources // the array of attached data source\n    swapId:  div id of the swap window \n});    dialog layout div id : the div where the dialog will be attached.     css: the dialog has a default style which can be overrided, this css will be added to the existing dialog css    show: you can show/hide the dialog    draggable: you would want to fix the dialog position    dockable: the dialog can be set to div, and can be move inside this div. If you undock the dialog, it will be attached directly to the document.body and not \nin the div anymore    closeable: display a button to close the dialog    connectionIds: since you can display a disconnect/connect button at the top of the dialog, this array is the link between the button and the data source concerned.\nWhen you click onto the disconnect button, the list of data source contains in this array will be disconnected (using DISCONNECT event of the Event Manager)    swapId: you can swap the content of the dialog with another div (body for example)    To set a view into a dialog, you can specify the div id of the dialog as argument div view Id such as:  var someDialog    = new OSH.UI.DialogView( dialog layout div id ,{\n    css:  your css dialog ,\n    name:  DialogName ,\n    show:false, // default show the dialog\n    draggable:true, // is the dialog is draggable?\n    dockable: false, // is the dialog is draggable?\n    closeable: true // is the dialog is closeable?,\n    connectionIds : dataSources // the array of attached data source\n    swapId:  div id of the swap window \n});\n\nvar someView = new OSH.UI.SomeView(someDialog.popContentDiv.id, [{...}],{...});  Thus the view will be automatically attached to the popContentDiv which is the dialog content. The best way to do that is to use the  attachTo()  function:  var someDialog    = new OSH.UI.DialogView( dialog layout div id ,{\n    css:  your css dialog ,\n    name:  DialogName ,\n    show:false, // default show the dialog\n    draggable:true, // is the dialog is draggable?\n    dockable: false, // is the dialog is draggable?\n    closeable: true // is the dialog is closeable?,\n    connectionIds : dataSources // the array of attached data source\n    swapId:  div id of the swap window \n});\n\nvar someView = new OSH.UI.SomeView( , [{...}],{...}); // it's important here to let the div id empty !!!\nsomeView.attachTo(someDialog.popContentDiv.id);  This will automatically set the view into the dialog. Note that it is very important in that case to let the view divId empty because we don't want to attach it to something.",
            "title": "Dialog"
        },
        {
            "location": "/dev/technical/#multidialogview",
            "text": "The multi dialog view is an extension of the Dialog view. It allows one to append div to an existing dialog:  var multiDialog    =  new OSH.UI.MultiDialogView( some container , {\n            draggable: true,\n            css:  dialog-multidialog ,\n            name:  Multi dialog ,\n            show:true,\n            dockable: false,\n            closeable: false,\n            connectionIds : [...]\n});\n\nvar someView = new OSH.UI.SomeView( , [{...}],{...}); // it's important here to let the div id empty !!!\nvar someView2 = new OSH.UI.SomeView( , [{...}],{...}); // it's important here to let the div id empty !!!\nvar someView3 = new OSH.UI.SomeView( , [{...}],{...}); // it's important here to let the div id empty !!!\n\n// attach the div view to the dialog\nsomeView.attachTo(multiDialog.popContentDiv.id);\n\nmultiDialog.appendView(someView2.divId);\nmultiDialog.appendView(someView3.divId);\n...  The someView 2   3 will be appended to the dialog. See the  Multi dialog + tasking example  of the Showcase",
            "title": "MultiDialogView"
        },
        {
            "location": "/dev/technical/#cesium-cesium-third-party-library",
            "text": "As we have seen, one can directly built Cesium in osh vendor using Gulp. One specific one has to take care is the Cesium global property:  window.CESIUM_BASE_URL = 'vendor/all-in-one';  Since Cesium will try to load by default the Cesium library from the  js  folder, if this one is located into another folder, you have to specify the  CESIUM_BASE_URL  to get it work.",
            "title": "Cesium (--cesium third party library)"
        },
        {
            "location": "/dev/technical/#ffmpeg-ffmpeg-third-party-library",
            "text": "The FFMPEG library is a pure native Javascript library. It is used decode video frame in native javascript code.  \"The original ffmpeg.js project provides FFmpeg builds ported to JavaScript using Emscripten project. Builds are optimized for in-browser use: minimal size for faster loading, asm.js, performance tunings, etc. Though they work in Node as well.\"  Source  By using this library, one can decode H264 video frame in the browser without using any additional plugins.\nA wrapper has been implemented within the Toolkit and provides some useful functionnalities such as:   Define canvas size  use webworker  increase performance by using transferable objects   One can use the  OSH.UI.FFMPEGView  and build the library using --ffmpeg argument to Gulp such as:  $ gulp build --ffmpeg  There are the default options of the View:  dataSourceId: videoDataSource.id,\ncss:  your css ,\ncssSelected:  you css after selecting the view ,\nname:  view name ,\nuseWorker: true|false ,\nuseWebWorkerTransferableData:  true|false  // this is because you can speed up the data transfert between main script and web worker\n                                            by using transferable data. Note that can cause problems if you data is attempted to use anywhere else.\n                                            See the not below for more details(*).  One can use the WebWorker which increases performance significantly since the decoding part is executed into a separated thread. It is very useful if several FFmpeg View are declared at the same time.  Another tip is to use the  useWebWorkerTransferableData  which allows to use transferable object directly between the main thread and the WebWorker.  This property can cause trouble if you share the same data into different view because the pointer is transferred to the webworker and becomes then unavailable in the main thread.  Without transferable object:  Data --  VIEW (data copied into)--  WebWorker  With transferable object:  Data --  VIEW (pointer transferred to)--  WebWorker  Not to copy the data increases the performance since transfert is much more faster.  If the data is only associated to one view, you should enable this parameter.  External resources:     https://developer.mozilla.org/en-US/docs/Web/API/Transferable  https://developer.mozilla.org/en/docs/Web/API/Worker/postMessage   If the webworker property is enabled, the view will also spawn a WebWorker. Since the WebWorker has to load the FFmpeg.js library separately, the worker library is placed in the  workers \nfolder built by the  Gulp build  command such as:  ... \n\n\u251c\u2500\u2500 js\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 osh.js\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 workers\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 ffmpeg-h264.js\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 osh-UI-FFMPEGViewWorker.js\n\n...         Using the WebWorker is meaning you have to keep this structure to get it work. The  workers  folder has to be right next to the  osh.js  file. The worker and the library are located at the same place.\nThe worker is loaded from the view as:  js/workers/osh-UI-FFMPEGViewWorker.js",
            "title": "FFMPEG (--ffmpeg third party library)"
        },
        {
            "location": "/dev/jsdoc/",
            "text": "JsDoc\n\n\nThe documentation has been generated using jsdoc. It can be found at: \nDocumentation",
            "title": "JSdoc"
        },
        {
            "location": "/dev/jsdoc/#jsdoc",
            "text": "The documentation has been generated using jsdoc. It can be found at:  Documentation",
            "title": "JsDoc"
        },
        {
            "location": "/tutos/osh-by-example/",
            "text": "Create the client \"Drone Real-time Video Draping onto Terrain\"\n\n\n1) Get information reading GetCapabilities\n\n\nThe first thing you have to do is to gather all the necessary information about your connection. The OSH server allows\none to get information through SOS, SOS-T etc. \n\n\nWhat we need is:\n\n\n1) Offering id\n\n\n2) ObservedProperty\n\n\n3) The time: can be a time range or real-time. A specific notation is used for real-time data\n\n\nThis \nlink\n will provide you more details about SOS.\n\n\nLet's say the endpoint is \nlocalhost:8181\n and the sos server \nsensorhub/sos\n.\n\n\nA getCapabitilies request would be\n\n\nhttp://localhost.net:8181/sensorhub/sos?service=SOS\nversion=2.0\nrequest=GetCapabilities\n\n\nThe next step is to extract the offeringId corresponding to our sensor:\n\n\n \nswes:offering\n\n    \nsos:ObservationOffering\n\n        \nswes:description\nArchive data from Solo Nav DataStore\n/swes:description\n\n        \nswes:identifier\nurn:osh:solo-nav\n/swes:identifier\n\n        \nswes:name\nSolo Nav DataStore\n/swes:name\n\n        \nswes:procedure\nurn:osh:sensor:mavlink:solo:S115A5800419\n/swes:procedure\n\n        \nswes:observableProperty\nhttp://www.opengis.net/def/property/OGC/0/PlatformOrientation\n/swes:observableProperty\n\n        \nswes:observableProperty\nhttp://sensorml.com/ont/swe/property/OSH/0/GimbalOrientation\n/swes:observableProperty\n\n        \nswes:observableProperty\nhttp://www.opengis.net/def/property/OGC/0/PlatformLocation\n/swes:observableProperty\n\n        \nsos:phenomenonTime\n\n            \ngml:TimePeriod gml:id=\nT4\n\n                \ngml:beginPosition\n2016-08-30T18:58:46.180Z\n/gml:beginPosition\n\n                \ngml:endPosition\n2016-08-30T19:20:17.002Z\n/gml:endPosition\n\n            \n/gml:TimePeriod\n\n        \n/sos:phenomenonTime\n\n        ...\n\n/swes:offering\n\n ```\n\nand\n\n```xml\n\nswes:offering\n\n    \nsos:ObservationOffering\n\n        \nswes:description\nArchive data from Solo Video DataStore\n/swes:description\n\n        \nswes:identifier\nurn:osh:solo-video\n/swes:identifier\n\n        \nswes:name\nSolo Video DataStore\n/swes:name\n\n        \nswes:procedure\nurn:osh:sensor:rtpcam:solo:S115A5800419\n/swes:procedure\n\n        \nswes:observableProperty\nhttp://sensorml.com/ont/swe/property/VideoFrame\n/swes:observableProperty\n\n        \nswes:observableProperty\nhttp://sensorml.com/ont/swe/property/Image\n/swes:observableProperty\n\n        \nsos:phenomenonTime\n\n            \ngml:TimePeriod gml:id=\nT5\n\n                \ngml:beginPosition\n2016-08-30T18:59:03.009Z\n/gml:beginPosition\n\n                \ngml:endPosition\n2016-08-30T19:20:16.402Z\n/gml:endPosition\n\n            \n/gml:TimePeriod\n\n        \n/sos:phenomenonTime\n\n        ...\n\n/swes:offering\n\n\n\n\n\nThen the relevant information is:\n\n\n\n\n\n\nOfferingId: \nurn:osh:solo-nav\n\n\n\n\n\n\nObservedProperty:\n\n\n\n\n\n\nhttp://www.opengis.net/def/property/OGC/0/PlatformOrientation\n\n\n\n\n\n\nhttp://sensorml.com/ont/swe/property/OSH/0/GimbalOrientation\n\n\n\n\n\n\nhttp://www.opengis.net/def/property/OGC/0/PlatformLocation\n\n\n\n\n\n\n\n\n\n\nTime range: from \n2016-08-30T18:58:46.180Z\n to \n2016-08-30T19:20:17.002Z\n\n\n\n\n\n\nFor the second sensor:\n\n\n\n\n\n\nOfferingId: \nurn:osh:solo-video\n\n\n\n\n\n\nObservedProperty:\n\n\n\n\n\n\nhttp://sensorml.com/ont/swe/property/VideoFrame\n\n\n\n\n\n\nhttp://sensorml.com/ont/swe/property/Image\n\n\n\n\n\n\n\n\n\n\nTime range: from \n2016-08-30T18:59:03.009Z\n to \n2016-08-30T19:20:16.402Z\n\n\n\n\n\n\n2) Use the right Javascript mappers\n\n\nOnce you have got the information, you have to use the Toolkit to build your client.\nYou have to choose the corresponding data receivers and the corresponding views:\n\n\nDataReceivers\n\n\n\n\n\n\nPlatformLocation =\n LatLon =\n textual including timestamp =\n \nOSH.DataReceiver.JSON\n. The generic\n  JSON parser is able to parse any textual data and separate the timestamp from the others\n\n\n\n\n\n\nGimbalOrientation =\n EulerOrientation =\n textual including timestamp =\n \nOSH.DataReceiver.JSON\n\n\n\n\n\n\nVideo (H264) =\n VideoH264 =\n binary data =\n \nOSH.DataReceiver. VideoH264\n\n\n\n\n\n\nViews\n\n\nTo represent the data, we will choose in this example:\n\n\n\n\n\n\nCesiumView =\n 3D map\u00a0\n\n\n\n\n\n\nDialogView =\n encapsulates video + chart viewers\n\n\n\n\n\n\nRangeSlider =\n control time\n\n\n\n\n\n\nNvd3CurveChartView =\n Chart\n\n\n\n\n\n\nFFMPEGView =\n Display Video using FFMPEG JS\n\n\n\n\n\n\nEntityTreeView =\n display entities\n\n\n\n\n\n\nStackMenu =\n for Tree\n\n\n\n\n\n\nThe views are not dependent of the data sources, many views can be used to represent the same data using a data receiver.\nObvioulsy, some views are more appropriate such as the FFmpegView which is only used to display H264 encoded frames.\n\n\n3) Define your HTML layout\n\n\nWe need three containers to render the views:\n\n\nbody\n\n \ndiv id=\nvideoViewDivId\n class=\nmini-view\n/div\n \n!-- Video View --\n\n \ndiv id=\nchartViewDivId\n class=\nmini-view\n/div\n \n!-- Chart View --\n\n \ndiv id=\ncesiumViewId\n class=\nmini-view\n/div\n \n!-- Cesium View --\n\n\n/body\n\n\n\n\n\n4) Create your JS code - DataReceivers\n\n\n// DEFINE TIME\nvar startTime = \n2016-08-30T19:00:40Z\n;\nvar endTime = \n2016-08-30T19:22:00Z\n;\nvar replaySpeed = \n1\n;\n\n// LatLon DataReceiver  \nvar soloGPS = new OSH.DataReceiver.JSON(\nSolo GPS\n, {\n    protocol : \nws\n,\n    service: \nSOS\n,\n    endpointUrl: hostname + \n/sensorhub/sos\n,\n    offeringID: \nurn:osh:solo-nav\n,\n    observedProperty: \nhttp://www.opengis.net/def/property/OGC/0/PlatformLocation\n,\n    startTime: startTime,\n    endTime: endTime,\n    replaySpeed: replaySpeed,\n    syncMasterTime: true // This specify to synchronize the data\n});\n\n// Orientation DataReceiver\nvar soloAttitude = new OSH.DataReceiver.JSON(\nSolo Attitude\n, {\n    protocol : \nws\n,\n    service: \nSOS\n,\n    endpointUrl: hostname + \n/sensorhub/sos\n,\n    offeringID: \nurn:osh:solo-nav\n,\n    observedProperty: \nhttp://www.opengis.net/def/property/OGC/0/PlatformOrientation\n,\n    startTime: startTime,\n    endTime: endTime,\n    replaySpeed: replaySpeed,\n    syncMasterTime: true\n});\n\n// Gimbal orientation DataReceiver\nvar soloGimbal = new OSH.DataReceiver.JSON(\nSolo Gimbal\n, {\n    protocol : \nws\n,\n    service: \nSOS\n,\n    endpointUrl: hostname + \n/sensorhub/sos\n,\n    offeringID: \nurn:osh:solo-nav\n,\n    observedProperty: \nhttp://sensorml.com/ont/swe/property/OSH/0/GimbalOrientation\n,\n    startTime: startTime,\n    endTime: endTime,\n    replaySpeed: replaySpeed,\n    syncMasterTime: true\n});\n\n\n\n// Video H264 DataReceiver\nvar soloVideo = new OSH.DataReceiver.VideoH264(\nSolo Video\n, {\n    protocol : \nws\n,\n    service: \nSOS\n,\n    endpointUrl: hostname + \n/sensorhub/sos\n,\n    offeringID: \nurn:osh:solo-video\n,\n    observedProperty: \nhttp://sensorml.com/ont/swe/property/VideoFrame\n,\n    startTime: startTime,\n    endTime: endTime,\n    replaySpeed: replaySpeed,\n    timeShift: -100,\n    syncMasterTime: true\n});\n\n\n\n\nWe define here a time range corresponding to the GetCapabilities information. As described above, we instantiate \nthree JSON generic data receiver and one binary.\n\n\nThe \nsyncMasterTime\n is an advanced tool provided by the Toolkit which allows to synchronize the data sources between them.\nThat means for every data received, the timestamp will be checked and ordered to be sure that for a given time \nt\n, the data \nis synchronized. In the case of the H264 binary data, the timeStamp is extracted from the first bytes of the stream, the raw data is then\nextracted by shifting the bytes of the timeStamp length.\n\n\nThe \noffering\n, \nobservedProperty\n and \nendpoint\n are the ones extracted from the GetCap request.\n\n\nEntity\n\n\nAnother useful tool is the entity. You can associate sensors between them. For example, if you know that \nsensors are from the same hardware, it can be useful to associate one sensor to each other.\nThe entity is a simple way to do that:\n\n\n//--------------------------------------------------------------//\n//-------------------------- Entities --------------------------//\n//--------------------------------------------------------------//\nvar soloEntity = {\n    id: \nsolo1\n,\n    name: \n3DR Solo\n,\n    dataSources: [soloGPS, soloAttitude, soloGimbal, soloVideo]\n};\n\n\n\n\nThe data sources are associated together.\n\n\nVideo view (--ffmpeg third party library)\n\n\nTo display the Video, you can use the FFMpeg view which has been specially created for displaying H264\nencoded frames.\n\n\n//--------------------------------------------------------------//\n//--------------------------- Views  ---------------------------//\n//--------------------------------------------------------------//\n\n\nvar soloVideoView = new OSH.UI.FFMPEGView(\nvideoViewDivId\n, {\n    dataSourceId: soloVideo.getId(),\n    entityId : soloEntity.id,\n    css: \nvideo\n,\n    cssSelected: \nvideo-selected\n,\n    useWorker: true,\n    width: 1280,\n    height: 720\n});\n\n\n\n\nThe view is then associated to a data source and an entity. It will create a div into the \nvideoViewDivId\n.\nThe css passed as argument will be used by the inner hidden created div of the view. The \ncssSelected\n properties\ncorrespond to a css which is applied when you click onto your view. For example, you can decide to highlight the border \nof your div with large width.\n\n\nThis view has a special property \nuseWorker\n which allows multithreading. The frame decoding will be processed \ninto a separate thread (using a WebWorker).\n\n\nChart view (--nvd3 third party library)\n\n\nTo display the altitude of the drone, you can use the simple chart view. By default, the toolkit provide a NDV3 view allowing \nto display curve chart:\n\n\n//--------------------------------------------------------------//\n//--------------------------- Views  ---------------------------//\n//--------------------------------------------------------------//\n\n\nvar altChartView = new OSH.UI.Nvd3CurveChartView(\nchartViewDivId\n,\n[{\n    styler: new OSH.UI.Styler.Curve({\n        valuesFunc: {\n            dataSourceIds: [soloGPS.getId()],\n            handler: function (rec, timeStamp) {\n                if (rec.alt \n 1)\n                    rec.alt *= 1e4; // *10^4 due to bug in Toulouse dataset\n                return {\n                    x: timeStamp,\n                    y: rec.alt+mslToWgs84\n                };\n            }\n        }\n    })\n}],\n{\n    dataSourceId: soloGPS.getId(),\n    yLabel: 'Altitude (m)',\n    xLabel: 'Time',\n    maxPoints: 100,\n    css:\nchart-view\n,\n    cssSelected: \nvideo-selected\n\n});\n\n\n\n\nIn this example, there are two interesting parts:\n\n\n1) the styler which is used to apply an altitude rectification\n\n\n2) the graph view properties (provided by the view itself)\n\n\nThe styler is fed directly by the OSH.EventManager. It is built from a dataSourceId array. When the\ndata have processed by the buffer, the \nOSH.EventManager\n will fire an event. The view will get\nthis event (if the data source id matches) and forward the data to the styler if it exists.\nThen the style acts like a filter, in this example, it is useful to rectify the data before displaying into the chart.\n\n\nThe \nvaluesFunc\n means \nfor each data..do\n. Each styler has a different way to handle data and has a different function \nsignature. Check the documentation for more details about them. You can use pre-existed styler or create yours.\n(\nStyler documentation\n)\n\n\nOther stylers\n\n\nNow you can define point marker styler to style Lat,Lon, Alt textual data:\n\n\n//--------------------------------------------------------------//\n//--------------------------- Views  ---------------------------//\n//--------------------------------------------------------------//\n\n// common point marker\nvar pointMarker = new OSH.UI.Styler.PointMarker({\n    label: \n3DR Solo\n,\n    locationFunc : {\n        dataSourceIds : [soloGPS.getId()],\n        handler : function(rec) {\n            if (rec.alt \n 1)\n                rec.alt *= 1e4; // *10^4 due to bug in Toulouse dataset\n            return {\n                x : rec.lon,\n                y : rec.lat,\n                z : rec.alt+mslToWgs84-5. // model offset\n            };\n        }\n    },\n    orientationFunc : {\n        dataSourceIds : [soloAttitude.getId()],\n        handler : function(rec) {\n            return {\n                heading : rec.heading\n            };\n        }\n    },\n    icon: \n./models/Drone+06B.glb\n\n});\n\n\n\n\nThis styler contains two functions, one for location and another one for orientation. Two different\ndata sources are needed to get this information.\nthe \nlocationFunc\n add MSL to LatLon data whereas the \norientationFunc\n extracts heading from altitude.\n\n\nDepending on the \nobserveProperty\n, the data can be provided in various ways. For example, let's suppose\nthe \nhttp://sensorml.com/ont/swe/property/OrientationQuaternion\n instead, this would have as result:\n\n\nvar pointMarker = new OSH.UI.Styler.PointMarker({\n    label: \n3DR Solo\n,\n    locationFunc : {\n        dataSourceIds : [soloGPS.getId()],\n        handler : function(rec) {\n            if (rec.alt \n 1)\n                rec.alt *= 1e4; // *10^4 due to bug in Toulouse dataset\n            return {\n                x : rec.lon,\n                y : rec.lat,\n                z : rec.alt+mslToWgs84-5. // model offset\n            };\n        }\n    },\n    orientationFunc : {\n        dataSourceIds : [soloAttitude.getId()],\n        handler : function(rec) {\n            var qx = rec.orient.qx;\n            var qy = rec.orient.qy;\n            var qz = rec.orient.qz;\n            var qw = rec.orient.q0;\n\n            // look dir vector\n            var x = 0;\n            var y = 0;\n            var z = -1;\n\n            // calculate quat * vector\n            var ix =  qw * x + qy * z - qz * y;\n            var iy =  qw * y + qz * x - qx * z;\n            var iz =  qw * z + qx * y - qy * x;\n            var iw = - qx * x - qy * y - qz * z;\n\n            // calculate result * inverse quat\n            xp = ix * qw + iw * - qx + iy * - qz - iz * - qy;\n            yp = iy * qw + iw * - qy + iz * - qx - ix * - qz;\n            zp = iz * qw + iw * - qz + ix * - qy - iy * - qx;\n\n            var yaw = 90 - (180/Math.PI*Math.atan2(yp, xp));\n\n            return {\n                heading : yaw\n            };\n        }\n    },\n    icon: \n./models/Drone+06B.glb\n\n});\n\n\n\n\nThe \nImageDraping\n styler looks like:\n\n\nvar imageDrapingStyler = new OSH.UI.Styler.ImageDraping({\n    platformLocationFunc: {\n        dataSourceIds: [soloGPS.getId()],\n        handler: function(rec) {\n            if (rec.alt \n 1)\n                rec.alt *= 1e4; // *10^4 due to bug in Toulouse dataset\n            return {\n                x: rec.lon,\n                y: rec.lat,\n                z: rec.alt + mslToWgs84\n            };\n        }\n    },\n    platformOrientationFunc: {\n        dataSourceIds: [soloAttitude.getId()],\n        handler: function(rec) {\n            return {\n                heading: rec.heading,\n                pitch: 0, //rec.pitch,\n                roll: 0, //rec.roll\n            };\n        }\n    },\n    gimbalOrientationFunc: {\n        dataSourceIds: [soloGimbal.getId()],\n        handler: function(rec) {\n            return {\n                heading: rec.heading,\n                pitch: -92, //rec.pitch,\n                roll: 0, //rec.roll\n            };\n        }\n    },\n    /*GoPro*/\n    cameraModel: {\n        camProj: new Cesium.Matrix3(747.963 / 1280., 0.0, 650.66 / 1280.,\n            0.0, 769.576 / 738., 373.206 / 738.,\n            0.0, 0.0, 1.0),\n        camDistR: new Cesium.Cartesian3(-2.644e-01, 8.4e-02, 0.0),\n        camDistT: new Cesium.Cartesian2(-8.688e-04, 6.123e-04)\n    },\n    imageSrc: $$('#' + soloVideoView.getId() + ' canvas')[0]\n});\n\n\n\n\nCesium view (--cesium third party library)\n\n\nNow you have setup the 3D view:\n\n\n var mapView = new OSH.UI.CesiumView(\ncesiumViewId\n, [\n{\n     name: \n3DR Solo\n,\n     entityId: soloEntity.id,\n     styler: pointMarkerStyler\n }, {\n     name: \nGeolocated Imagery\n,\n     entityId: soloEntity.id,\n     styler: imageDrapingStyler\n }]);\n\n\n\n\nMost of the views are composed from \nViewItems\n. They are passed as array argument to the view.\nA \nviewItem\n contains a \nname\n,\nentityId\n and a  \nstyler\n.\n\n\nData receiver controller\n\n\nAs described above, you can use a data receiver controller to wrap and abstract some logic. The data source\ncan be connected/disconnected directly by calling the \nconnect\n/\ndisconnect\n function as well.\n\n\nvar dataSourceController = new OSH.DataReceiver.DataReceiverController({\n        replayFactor: 1.0\n});\n\ndataSourceController.addEntity(soloEntity);\ndataSourceController.connectAll();\n// or fire an event\n//OSH.EventManager.fire(OSH.EventManager.EVENT.CONNECT_DATASOURCE, {dataSourcesId:[videoDataSource.id]});\n\n\n\n\nExtras features\n\n\nThe Toolkit provides a set of extra features that help you to simplify the way to develop your Application such as:\n\n\n\n\n\n\nDecorate container using floating dialog windows\n\n\n\n\n\n\nAdd contextual menu\n\n\n\n\n\n\nAdd entity tree viewer\n\n\n\n\n\n\nAdd range slider\n\n\n\n\n\n\nDialog Window\n\n\nThe Dialog window can decorate any div. It's a floating window with useful actions:\n\n\n\n\n\n\ndock: can dock the window\n\n\n\n\n\n\ndrag: can drag the window\n\n\n\n\n\n\nclose: can close the window\n\n\n\n\n\n\nswap: swap the inner content with another div (background for example)\n\n\n\n\n\n\nshow/hide\n\n\n\n\n\n\nconnect/disconnect: can disconnect/disconnect associated data source\n\n\n\n\n\n\nFor that, you need a HTML layout:\n\n\ndiv id=\nmain-container\n class=\nmain-view\n/div\n\n\ndiv id=\ndialog-main-container\n class=\nvideo-main-container\n/div\n\n\n\n\n\nIf you want to decorate a view, you have to put the viewId into the dialog:\n\n\n// video view    \nvar soloVideoDialog = new OSH.UI.DialogView(\ndialog-main-container\n, { // put the dialog to the main container\n    draggable: false,\n    css: \nvideo-dialog\n,\n    name: \nUAV Video\n,\n    show: true,\n    dockable: true,\n    closeable: true,\n    canDisconnect : false,\n    swapId: \nmain-container\n\n});\n\nvar soloVideoView = new OSH.UI.FFMPEGView(soloVideoDialog.popContentDiv.id, { // put the view into the dialog\n    dataSourceId: soloVideo.getId(),\n    entityId : soloEntity.id,\n    css: \nvideo\n,\n    cssSelected: \nvideo-selected\n,\n    useWorker: true,\n    width: 1280,\n    height: 720\n});\n\n// chart view\nvar altChartDialog = new OSH.UI.DialogView(\ndialog-main-container\n, {\n    draggable: false,\n    css: \ndialog\n,\n    name: \nSolo Altitude\n,\n    show: false,\n    dockable: true,\n    closeable: true,\n    canDisconnect : false,\n    swapId: \nmain-container\n\n});\n\nvar altChartView = new OSH.UI.Nvd3CurveChartView(altChartDialog.popContentDiv.id, ...);\n\n// Cesium view is plugged as background \nvar mapView = new OSH.UI.CesiumView(\nmain-container\n,...)\n\n\n\n\nContext Menu\n\n\nAnother useful is the context menu. They add a contextual menu onto some views and can be associated with actions.\nThey receive and send events using the EventManager. They are built from \nmenuItem\n and can be grouped by a \ngroupId\n.\n\n\nThe \nviewItem\n of a view has a property to associate a context menu,for example:\n\n\n// menu ids\nvar soloTreeMenuId = \nsolo-tree-menu\n;\nvar soloMarkerMenuId = \nsolo-marker-menu\n;\nvar menuGroupId = \nallmenus\n;\n\n// cesium map view\nvar mapView = new OSH.UI.CesiumView(\nmain-container\n, [{\n  name: \n3DR Solo\n,\n  entityId: soloEntity.id,\n  styler: pointMarker,\n  contextMenuId: soloMarkerMenuId // adds context menu to cesiumView\n}\n[...]\n\n\n\n\nNow you have to define your \nmenuItem\n:\n\n\nvar menuItems = [{\n    name: \nShow Video\n,\n    viewId: soloVideoDialog.getId(),\n    css: \nfa fa-video-camera\n,\n    action: \nshow\n //Can also use EventManager: OSH.EventManager.EVENT.SHOW_VIEW\n}, {\n    name: \nShow Altitude Chart\n,\n    viewId: altChartDialog.getId(),\n    css: \nfa fa-bar-chart\n,\n    action: \nshow\n\n}, {\n    name: \nTakeOff\n,\n    viewId: \n,\n    css: \nfa fa-upload\n,\n    action: \nuav:takeoff\n\n}, {\n    name: \nLand\n,\n    viewId: \n,\n    css: \nfa fa-download\n,\n    action: \nuav:land\n\n}];\n\nvar markerMenu = new OSH.UI.ContextMenu.CircularMenu({\n    id: soloMarkerMenuId,\n    groupId: menuGroupId,\n    items: menuItems\n});\n\n\n\n\nIn this example, we use an existing CircularMenu displaying a circle with some actions.\n\n\nEntity Tree viewer (--tree third party library)\n\n\nThe Entity Tree viewer (provided by the external \ntree\n library) shows the whole list of entities and their \nassociated data receivers. It has a stack menu to perform actions and inherit from the \nOSH.UI.View\n.\nMoreover, you can render the tree into a Dialog:\n\n\n // tree view\nvar entityTreeDialog = new OSH.UI.DialogView(document.body.id, {\n    css: \ntree-dialog\n,\n    name: \nEntities\n,\n    show: true,\n    draggable: true,\n    dockable: false,\n    closeable: true\n});\n\nvar entityTreeView = new OSH.UI.EntityTreeView(entityTreeDialog.popContentDiv.id,\n    [{\n        entity : soloEntity,\n        path: \nSensors/Solo\n,\n        treeIcon : \nimages/drone.png\n,\n        contextMenuId: soloTreeMenuId\n    }],\n    {\n        css: \ntree-container\n\n    }\n);    \n\n\n\n\nRange Slider (--nouislider third party library)\n\n\nThe range slider allows one to control change the time period. It sends events to change dynamically DataReceiver request  and\nalso use the EventManager to listen to data.\n\n\nIt supports playback data as well as real-time data (time period cannot be changed in that mode).\n\n\nLet's take an example:\n\n\nHtml Layout:\n\n\ndiv class=\nrangeSlider-container\n\n    \ndiv id=\nrangeSlider\n class=\nrangeSlider\n/div\n\n\n/div\n\n\n\n\n\nSince it uses EventManager to communicate, you have only to instantiate a new Object\n\n\n var rangeSlider = new OSH.UI.RangeSlider(\nrangeSlider\n,{\n    startTime: \n2015-02-16T07:58:00Z\n,\n    endTime: \n2015-02-16T08:09:00Z\n,\n    refreshRate:1\n});\n\n\n\n\nFor real-time we would set:\n\n\n var rangeSlider = new OSH.UI.RangeSlider(\nrangeSlider\n);",
            "title": "OSH by example"
        },
        {
            "location": "/tutos/osh-by-example/#create-the-client-drone-real-time-video-draping-onto-terrain",
            "text": "",
            "title": "Create the client \"Drone Real-time Video Draping onto Terrain\""
        },
        {
            "location": "/tutos/osh-by-example/#1-get-information-reading-getcapabilities",
            "text": "The first thing you have to do is to gather all the necessary information about your connection. The OSH server allows\none to get information through SOS, SOS-T etc.   What we need is:  1) Offering id  2) ObservedProperty  3) The time: can be a time range or real-time. A specific notation is used for real-time data  This  link  will provide you more details about SOS.  Let's say the endpoint is  localhost:8181  and the sos server  sensorhub/sos .  A getCapabitilies request would be  http://localhost.net:8181/sensorhub/sos?service=SOS version=2.0 request=GetCapabilities  The next step is to extract the offeringId corresponding to our sensor:    swes:offering \n     sos:ObservationOffering \n         swes:description Archive data from Solo Nav DataStore /swes:description \n         swes:identifier urn:osh:solo-nav /swes:identifier \n         swes:name Solo Nav DataStore /swes:name \n         swes:procedure urn:osh:sensor:mavlink:solo:S115A5800419 /swes:procedure \n         swes:observableProperty http://www.opengis.net/def/property/OGC/0/PlatformOrientation /swes:observableProperty \n         swes:observableProperty http://sensorml.com/ont/swe/property/OSH/0/GimbalOrientation /swes:observableProperty \n         swes:observableProperty http://www.opengis.net/def/property/OGC/0/PlatformLocation /swes:observableProperty \n         sos:phenomenonTime \n             gml:TimePeriod gml:id= T4 \n                 gml:beginPosition 2016-08-30T18:58:46.180Z /gml:beginPosition \n                 gml:endPosition 2016-08-30T19:20:17.002Z /gml:endPosition \n             /gml:TimePeriod \n         /sos:phenomenonTime \n        ... /swes:offering \n ```\n\nand\n\n```xml swes:offering \n     sos:ObservationOffering \n         swes:description Archive data from Solo Video DataStore /swes:description \n         swes:identifier urn:osh:solo-video /swes:identifier \n         swes:name Solo Video DataStore /swes:name \n         swes:procedure urn:osh:sensor:rtpcam:solo:S115A5800419 /swes:procedure \n         swes:observableProperty http://sensorml.com/ont/swe/property/VideoFrame /swes:observableProperty \n         swes:observableProperty http://sensorml.com/ont/swe/property/Image /swes:observableProperty \n         sos:phenomenonTime \n             gml:TimePeriod gml:id= T5 \n                 gml:beginPosition 2016-08-30T18:59:03.009Z /gml:beginPosition \n                 gml:endPosition 2016-08-30T19:20:16.402Z /gml:endPosition \n             /gml:TimePeriod \n         /sos:phenomenonTime \n        ... /swes:offering   Then the relevant information is:    OfferingId:  urn:osh:solo-nav    ObservedProperty:    http://www.opengis.net/def/property/OGC/0/PlatformOrientation    http://sensorml.com/ont/swe/property/OSH/0/GimbalOrientation    http://www.opengis.net/def/property/OGC/0/PlatformLocation      Time range: from  2016-08-30T18:58:46.180Z  to  2016-08-30T19:20:17.002Z    For the second sensor:    OfferingId:  urn:osh:solo-video    ObservedProperty:    http://sensorml.com/ont/swe/property/VideoFrame    http://sensorml.com/ont/swe/property/Image      Time range: from  2016-08-30T18:59:03.009Z  to  2016-08-30T19:20:16.402Z",
            "title": "1) Get information reading GetCapabilities"
        },
        {
            "location": "/tutos/osh-by-example/#2-use-the-right-javascript-mappers",
            "text": "Once you have got the information, you have to use the Toolkit to build your client.\nYou have to choose the corresponding data receivers and the corresponding views:",
            "title": "2) Use the right Javascript mappers"
        },
        {
            "location": "/tutos/osh-by-example/#datareceivers",
            "text": "PlatformLocation =  LatLon =  textual including timestamp =   OSH.DataReceiver.JSON . The generic\n  JSON parser is able to parse any textual data and separate the timestamp from the others    GimbalOrientation =  EulerOrientation =  textual including timestamp =   OSH.DataReceiver.JSON    Video (H264) =  VideoH264 =  binary data =   OSH.DataReceiver. VideoH264",
            "title": "DataReceivers"
        },
        {
            "location": "/tutos/osh-by-example/#views",
            "text": "To represent the data, we will choose in this example:    CesiumView =  3D map\u00a0    DialogView =  encapsulates video + chart viewers    RangeSlider =  control time    Nvd3CurveChartView =  Chart    FFMPEGView =  Display Video using FFMPEG JS    EntityTreeView =  display entities    StackMenu =  for Tree    The views are not dependent of the data sources, many views can be used to represent the same data using a data receiver.\nObvioulsy, some views are more appropriate such as the FFmpegView which is only used to display H264 encoded frames.",
            "title": "Views"
        },
        {
            "location": "/tutos/osh-by-example/#3-define-your-html-layout",
            "text": "We need three containers to render the views:  body \n  div id= videoViewDivId  class= mini-view /div   !-- Video View -- \n  div id= chartViewDivId  class= mini-view /div   !-- Chart View -- \n  div id= cesiumViewId  class= mini-view /div   !-- Cesium View --  /body",
            "title": "3) Define your HTML layout"
        },
        {
            "location": "/tutos/osh-by-example/#4-create-your-js-code-datareceivers",
            "text": "// DEFINE TIME\nvar startTime =  2016-08-30T19:00:40Z ;\nvar endTime =  2016-08-30T19:22:00Z ;\nvar replaySpeed =  1 ;\n\n// LatLon DataReceiver  \nvar soloGPS = new OSH.DataReceiver.JSON( Solo GPS , {\n    protocol :  ws ,\n    service:  SOS ,\n    endpointUrl: hostname +  /sensorhub/sos ,\n    offeringID:  urn:osh:solo-nav ,\n    observedProperty:  http://www.opengis.net/def/property/OGC/0/PlatformLocation ,\n    startTime: startTime,\n    endTime: endTime,\n    replaySpeed: replaySpeed,\n    syncMasterTime: true // This specify to synchronize the data\n});\n\n// Orientation DataReceiver\nvar soloAttitude = new OSH.DataReceiver.JSON( Solo Attitude , {\n    protocol :  ws ,\n    service:  SOS ,\n    endpointUrl: hostname +  /sensorhub/sos ,\n    offeringID:  urn:osh:solo-nav ,\n    observedProperty:  http://www.opengis.net/def/property/OGC/0/PlatformOrientation ,\n    startTime: startTime,\n    endTime: endTime,\n    replaySpeed: replaySpeed,\n    syncMasterTime: true\n});\n\n// Gimbal orientation DataReceiver\nvar soloGimbal = new OSH.DataReceiver.JSON( Solo Gimbal , {\n    protocol :  ws ,\n    service:  SOS ,\n    endpointUrl: hostname +  /sensorhub/sos ,\n    offeringID:  urn:osh:solo-nav ,\n    observedProperty:  http://sensorml.com/ont/swe/property/OSH/0/GimbalOrientation ,\n    startTime: startTime,\n    endTime: endTime,\n    replaySpeed: replaySpeed,\n    syncMasterTime: true\n});\n\n\n\n// Video H264 DataReceiver\nvar soloVideo = new OSH.DataReceiver.VideoH264( Solo Video , {\n    protocol :  ws ,\n    service:  SOS ,\n    endpointUrl: hostname +  /sensorhub/sos ,\n    offeringID:  urn:osh:solo-video ,\n    observedProperty:  http://sensorml.com/ont/swe/property/VideoFrame ,\n    startTime: startTime,\n    endTime: endTime,\n    replaySpeed: replaySpeed,\n    timeShift: -100,\n    syncMasterTime: true\n});  We define here a time range corresponding to the GetCapabilities information. As described above, we instantiate \nthree JSON generic data receiver and one binary.  The  syncMasterTime  is an advanced tool provided by the Toolkit which allows to synchronize the data sources between them.\nThat means for every data received, the timestamp will be checked and ordered to be sure that for a given time  t , the data \nis synchronized. In the case of the H264 binary data, the timeStamp is extracted from the first bytes of the stream, the raw data is then\nextracted by shifting the bytes of the timeStamp length.  The  offering ,  observedProperty  and  endpoint  are the ones extracted from the GetCap request.",
            "title": "4) Create your JS code - DataReceivers"
        },
        {
            "location": "/tutos/osh-by-example/#entity",
            "text": "Another useful tool is the entity. You can associate sensors between them. For example, if you know that \nsensors are from the same hardware, it can be useful to associate one sensor to each other.\nThe entity is a simple way to do that:  //--------------------------------------------------------------//\n//-------------------------- Entities --------------------------//\n//--------------------------------------------------------------//\nvar soloEntity = {\n    id:  solo1 ,\n    name:  3DR Solo ,\n    dataSources: [soloGPS, soloAttitude, soloGimbal, soloVideo]\n};  The data sources are associated together.",
            "title": "Entity"
        },
        {
            "location": "/tutos/osh-by-example/#video-view-ffmpeg-third-party-library",
            "text": "To display the Video, you can use the FFMpeg view which has been specially created for displaying H264\nencoded frames.  //--------------------------------------------------------------//\n//--------------------------- Views  ---------------------------//\n//--------------------------------------------------------------//\n\n\nvar soloVideoView = new OSH.UI.FFMPEGView( videoViewDivId , {\n    dataSourceId: soloVideo.getId(),\n    entityId : soloEntity.id,\n    css:  video ,\n    cssSelected:  video-selected ,\n    useWorker: true,\n    width: 1280,\n    height: 720\n});  The view is then associated to a data source and an entity. It will create a div into the  videoViewDivId .\nThe css passed as argument will be used by the inner hidden created div of the view. The  cssSelected  properties\ncorrespond to a css which is applied when you click onto your view. For example, you can decide to highlight the border \nof your div with large width.  This view has a special property  useWorker  which allows multithreading. The frame decoding will be processed \ninto a separate thread (using a WebWorker).",
            "title": "Video view (--ffmpeg third party library)"
        },
        {
            "location": "/tutos/osh-by-example/#chart-view-nvd3-third-party-library",
            "text": "To display the altitude of the drone, you can use the simple chart view. By default, the toolkit provide a NDV3 view allowing \nto display curve chart:  //--------------------------------------------------------------//\n//--------------------------- Views  ---------------------------//\n//--------------------------------------------------------------//\n\n\nvar altChartView = new OSH.UI.Nvd3CurveChartView( chartViewDivId ,\n[{\n    styler: new OSH.UI.Styler.Curve({\n        valuesFunc: {\n            dataSourceIds: [soloGPS.getId()],\n            handler: function (rec, timeStamp) {\n                if (rec.alt   1)\n                    rec.alt *= 1e4; // *10^4 due to bug in Toulouse dataset\n                return {\n                    x: timeStamp,\n                    y: rec.alt+mslToWgs84\n                };\n            }\n        }\n    })\n}],\n{\n    dataSourceId: soloGPS.getId(),\n    yLabel: 'Altitude (m)',\n    xLabel: 'Time',\n    maxPoints: 100,\n    css: chart-view ,\n    cssSelected:  video-selected \n});  In this example, there are two interesting parts:  1) the styler which is used to apply an altitude rectification  2) the graph view properties (provided by the view itself)  The styler is fed directly by the OSH.EventManager. It is built from a dataSourceId array. When the\ndata have processed by the buffer, the  OSH.EventManager  will fire an event. The view will get\nthis event (if the data source id matches) and forward the data to the styler if it exists.\nThen the style acts like a filter, in this example, it is useful to rectify the data before displaying into the chart.  The  valuesFunc  means  for each data..do . Each styler has a different way to handle data and has a different function \nsignature. Check the documentation for more details about them. You can use pre-existed styler or create yours.\n( Styler documentation )",
            "title": "Chart view (--nvd3 third party library)"
        },
        {
            "location": "/tutos/osh-by-example/#other-stylers",
            "text": "Now you can define point marker styler to style Lat,Lon, Alt textual data:  //--------------------------------------------------------------//\n//--------------------------- Views  ---------------------------//\n//--------------------------------------------------------------//\n\n// common point marker\nvar pointMarker = new OSH.UI.Styler.PointMarker({\n    label:  3DR Solo ,\n    locationFunc : {\n        dataSourceIds : [soloGPS.getId()],\n        handler : function(rec) {\n            if (rec.alt   1)\n                rec.alt *= 1e4; // *10^4 due to bug in Toulouse dataset\n            return {\n                x : rec.lon,\n                y : rec.lat,\n                z : rec.alt+mslToWgs84-5. // model offset\n            };\n        }\n    },\n    orientationFunc : {\n        dataSourceIds : [soloAttitude.getId()],\n        handler : function(rec) {\n            return {\n                heading : rec.heading\n            };\n        }\n    },\n    icon:  ./models/Drone+06B.glb \n});  This styler contains two functions, one for location and another one for orientation. Two different\ndata sources are needed to get this information.\nthe  locationFunc  add MSL to LatLon data whereas the  orientationFunc  extracts heading from altitude.  Depending on the  observeProperty , the data can be provided in various ways. For example, let's suppose\nthe  http://sensorml.com/ont/swe/property/OrientationQuaternion  instead, this would have as result:  var pointMarker = new OSH.UI.Styler.PointMarker({\n    label:  3DR Solo ,\n    locationFunc : {\n        dataSourceIds : [soloGPS.getId()],\n        handler : function(rec) {\n            if (rec.alt   1)\n                rec.alt *= 1e4; // *10^4 due to bug in Toulouse dataset\n            return {\n                x : rec.lon,\n                y : rec.lat,\n                z : rec.alt+mslToWgs84-5. // model offset\n            };\n        }\n    },\n    orientationFunc : {\n        dataSourceIds : [soloAttitude.getId()],\n        handler : function(rec) {\n            var qx = rec.orient.qx;\n            var qy = rec.orient.qy;\n            var qz = rec.orient.qz;\n            var qw = rec.orient.q0;\n\n            // look dir vector\n            var x = 0;\n            var y = 0;\n            var z = -1;\n\n            // calculate quat * vector\n            var ix =  qw * x + qy * z - qz * y;\n            var iy =  qw * y + qz * x - qx * z;\n            var iz =  qw * z + qx * y - qy * x;\n            var iw = - qx * x - qy * y - qz * z;\n\n            // calculate result * inverse quat\n            xp = ix * qw + iw * - qx + iy * - qz - iz * - qy;\n            yp = iy * qw + iw * - qy + iz * - qx - ix * - qz;\n            zp = iz * qw + iw * - qz + ix * - qy - iy * - qx;\n\n            var yaw = 90 - (180/Math.PI*Math.atan2(yp, xp));\n\n            return {\n                heading : yaw\n            };\n        }\n    },\n    icon:  ./models/Drone+06B.glb \n});  The  ImageDraping  styler looks like:  var imageDrapingStyler = new OSH.UI.Styler.ImageDraping({\n    platformLocationFunc: {\n        dataSourceIds: [soloGPS.getId()],\n        handler: function(rec) {\n            if (rec.alt   1)\n                rec.alt *= 1e4; // *10^4 due to bug in Toulouse dataset\n            return {\n                x: rec.lon,\n                y: rec.lat,\n                z: rec.alt + mslToWgs84\n            };\n        }\n    },\n    platformOrientationFunc: {\n        dataSourceIds: [soloAttitude.getId()],\n        handler: function(rec) {\n            return {\n                heading: rec.heading,\n                pitch: 0, //rec.pitch,\n                roll: 0, //rec.roll\n            };\n        }\n    },\n    gimbalOrientationFunc: {\n        dataSourceIds: [soloGimbal.getId()],\n        handler: function(rec) {\n            return {\n                heading: rec.heading,\n                pitch: -92, //rec.pitch,\n                roll: 0, //rec.roll\n            };\n        }\n    },\n    /*GoPro*/\n    cameraModel: {\n        camProj: new Cesium.Matrix3(747.963 / 1280., 0.0, 650.66 / 1280.,\n            0.0, 769.576 / 738., 373.206 / 738.,\n            0.0, 0.0, 1.0),\n        camDistR: new Cesium.Cartesian3(-2.644e-01, 8.4e-02, 0.0),\n        camDistT: new Cesium.Cartesian2(-8.688e-04, 6.123e-04)\n    },\n    imageSrc: $$('#' + soloVideoView.getId() + ' canvas')[0]\n});",
            "title": "Other stylers"
        },
        {
            "location": "/tutos/osh-by-example/#cesium-view-cesium-third-party-library",
            "text": "Now you have setup the 3D view:   var mapView = new OSH.UI.CesiumView( cesiumViewId , [\n{\n     name:  3DR Solo ,\n     entityId: soloEntity.id,\n     styler: pointMarkerStyler\n }, {\n     name:  Geolocated Imagery ,\n     entityId: soloEntity.id,\n     styler: imageDrapingStyler\n }]);  Most of the views are composed from  ViewItems . They are passed as array argument to the view.\nA  viewItem  contains a  name , entityId  and a   styler .",
            "title": "Cesium view (--cesium third party library)"
        },
        {
            "location": "/tutos/osh-by-example/#data-receiver-controller",
            "text": "As described above, you can use a data receiver controller to wrap and abstract some logic. The data source\ncan be connected/disconnected directly by calling the  connect / disconnect  function as well.  var dataSourceController = new OSH.DataReceiver.DataReceiverController({\n        replayFactor: 1.0\n});\n\ndataSourceController.addEntity(soloEntity);\ndataSourceController.connectAll();\n// or fire an event\n//OSH.EventManager.fire(OSH.EventManager.EVENT.CONNECT_DATASOURCE, {dataSourcesId:[videoDataSource.id]});",
            "title": "Data receiver controller"
        },
        {
            "location": "/tutos/osh-by-example/#extras-features",
            "text": "The Toolkit provides a set of extra features that help you to simplify the way to develop your Application such as:    Decorate container using floating dialog windows    Add contextual menu    Add entity tree viewer    Add range slider",
            "title": "Extras features"
        },
        {
            "location": "/tutos/osh-by-example/#dialog-window",
            "text": "The Dialog window can decorate any div. It's a floating window with useful actions:    dock: can dock the window    drag: can drag the window    close: can close the window    swap: swap the inner content with another div (background for example)    show/hide    connect/disconnect: can disconnect/disconnect associated data source    For that, you need a HTML layout:  div id= main-container  class= main-view /div  div id= dialog-main-container  class= video-main-container /div   If you want to decorate a view, you have to put the viewId into the dialog:  // video view    \nvar soloVideoDialog = new OSH.UI.DialogView( dialog-main-container , { // put the dialog to the main container\n    draggable: false,\n    css:  video-dialog ,\n    name:  UAV Video ,\n    show: true,\n    dockable: true,\n    closeable: true,\n    canDisconnect : false,\n    swapId:  main-container \n});\n\nvar soloVideoView = new OSH.UI.FFMPEGView(soloVideoDialog.popContentDiv.id, { // put the view into the dialog\n    dataSourceId: soloVideo.getId(),\n    entityId : soloEntity.id,\n    css:  video ,\n    cssSelected:  video-selected ,\n    useWorker: true,\n    width: 1280,\n    height: 720\n});\n\n// chart view\nvar altChartDialog = new OSH.UI.DialogView( dialog-main-container , {\n    draggable: false,\n    css:  dialog ,\n    name:  Solo Altitude ,\n    show: false,\n    dockable: true,\n    closeable: true,\n    canDisconnect : false,\n    swapId:  main-container \n});\n\nvar altChartView = new OSH.UI.Nvd3CurveChartView(altChartDialog.popContentDiv.id, ...);\n\n// Cesium view is plugged as background \nvar mapView = new OSH.UI.CesiumView( main-container ,...)",
            "title": "Dialog Window"
        },
        {
            "location": "/tutos/osh-by-example/#entity-tree-viewer-tree-third-party-library",
            "text": "The Entity Tree viewer (provided by the external  tree  library) shows the whole list of entities and their \nassociated data receivers. It has a stack menu to perform actions and inherit from the  OSH.UI.View .\nMoreover, you can render the tree into a Dialog:   // tree view\nvar entityTreeDialog = new OSH.UI.DialogView(document.body.id, {\n    css:  tree-dialog ,\n    name:  Entities ,\n    show: true,\n    draggable: true,\n    dockable: false,\n    closeable: true\n});\n\nvar entityTreeView = new OSH.UI.EntityTreeView(entityTreeDialog.popContentDiv.id,\n    [{\n        entity : soloEntity,\n        path:  Sensors/Solo ,\n        treeIcon :  images/drone.png ,\n        contextMenuId: soloTreeMenuId\n    }],\n    {\n        css:  tree-container \n    }\n);",
            "title": "Entity Tree viewer (--tree third party library)"
        },
        {
            "location": "/tutos/osh-by-example/#range-slider-nouislider-third-party-library",
            "text": "The range slider allows one to control change the time period. It sends events to change dynamically DataReceiver request  and\nalso use the EventManager to listen to data.  It supports playback data as well as real-time data (time period cannot be changed in that mode).  Let's take an example:  Html Layout:  div class= rangeSlider-container \n     div id= rangeSlider  class= rangeSlider /div  /div   Since it uses EventManager to communicate, you have only to instantiate a new Object   var rangeSlider = new OSH.UI.RangeSlider( rangeSlider ,{\n    startTime:  2015-02-16T07:58:00Z ,\n    endTime:  2015-02-16T08:09:00Z ,\n    refreshRate:1\n});  For real-time we would set:   var rangeSlider = new OSH.UI.RangeSlider( rangeSlider );",
            "title": "Range Slider (--nouislider third party library)"
        },
        {
            "location": "/tutos/osh-by-example-2/",
            "text": "Make your own data receiver\n\n\nGetCapabitlities\n\n\nLet's suppose we have the following information:\n\n\n\n\n\n\nofferingId: \nfake-offering\n\n\n\n\n\n\nstartTime: \n2016-08-30T19:00:40Z\n\n\n\n\n\n\nendTime: \n2016-08-30T19:22:00Z\n\n\n\n\n\n\nobservedProperty: \nhttp://www.opengis.net/def/property/OGC/0/PlatformLocation\n\n\n\n\n\n\nThe sos result stream looks like \ntimeStamp,fakeLat,fakeLon,fakeAlt\n\n\nCreate the new MyFakeLatLonAlt DataReceiver\n\n\nThe idea is to extract the timestamp and the date from the textual stream. The \nOSH.DataReceiver.DataSource\n can be extended:\n\n\nOSH.DataReceiver.MyFakeLatLonAlt= OSH.DataReceiver.DataSource.extend({\n\n    parseTimeStamp: function($super,data){\n        // do something\n        // this part extracts the timestamp \n        // the data could be text, binary etc..\n    },\n\n    parseData: function($super,data){\n        // do something\n        // this part extracts only the data without timestamp\n    }\n});\n\n\n\n\nExtract the timeStamp\n\n\nEvery data sent by the server includes a timestamp, the client has to extract it. In this example, the server \ncould send something like \n\"1977-04-22T06:00:00Z,2.464,5.278,30.0\"\n:\n\n\nparseTimeStamp: function($super,data){\n    // get record from websocket\n    var record = String.fromCharCode.apply(null, new Uint8Array(data));\n\n    // split the record using \n,\n as separator\n    var tokens = record.trim().split(\n,\n);\n\n    // return the timeStamp using Data JS Object and getTime (milliseconds)\n    return new Date(tokens[0]).getTime();\n}\n\n\n\n\nExtract the data\n\n\nYou need now to extract the \n2.464,5.278,30.0\n part:\n\n\nparseData: function($super,data){\n    // get data from WebSocket\n    var record = String.fromCharCode.apply(null, new Uint8Array(data));\n\n    // split String using \n,\n as separator\n    var tokens = record.trim().split(\n,\n);\n\n    // get lat, lon, alt\n    var lat = parseFloat(tokens[1]);\n    var lon = parseFloat(tokens[2]);\n    var alt = parseFloat(tokens[3]);\n\n    // return JS object\n    return {\n      lat : lat,\n      lon : lon,\n      alt : alt\n    };\n} \n\n\n\n\nInstantiate your new DataReceiver\n\n\nYou can now instantiate your new class:\n\n\nvar myFakeLatLonAlt = new OSH.DataReceiver.MyFakeLatLonAlt(\nFake GPS\n, {\n    protocol : \nws\n,\n    service: \nSOS\n,\n    endpointUrl: hostname + \n/sensorhub/sos\n,\n    offeringID: \nfake-offering\n, // the corresponding offering\n    observedProperty: \nhttp://www.opengis.net/def/property/OGC/0/PlatformLocation\n,\n    startTime: \n2016-08-30T19:00:40Z\n,\n    endTime: \n2016-08-30T19:22:00Z\n,\n    replaySpeed: 1,\n    syncMasterTime: true\n});",
            "title": "Make your own data receiver"
        },
        {
            "location": "/tutos/osh-by-example-2/#make-your-own-data-receiver",
            "text": "",
            "title": "Make your own data receiver"
        },
        {
            "location": "/tutos/osh-by-example-2/#getcapabitlities",
            "text": "Let's suppose we have the following information:    offeringId:  fake-offering    startTime:  2016-08-30T19:00:40Z    endTime:  2016-08-30T19:22:00Z    observedProperty:  http://www.opengis.net/def/property/OGC/0/PlatformLocation    The sos result stream looks like  timeStamp,fakeLat,fakeLon,fakeAlt",
            "title": "GetCapabitlities"
        },
        {
            "location": "/tutos/osh-by-example-2/#create-the-new-myfakelatlonalt-datareceiver",
            "text": "The idea is to extract the timestamp and the date from the textual stream. The  OSH.DataReceiver.DataSource  can be extended:  OSH.DataReceiver.MyFakeLatLonAlt= OSH.DataReceiver.DataSource.extend({\n\n    parseTimeStamp: function($super,data){\n        // do something\n        // this part extracts the timestamp \n        // the data could be text, binary etc..\n    },\n\n    parseData: function($super,data){\n        // do something\n        // this part extracts only the data without timestamp\n    }\n});",
            "title": "Create the new MyFakeLatLonAlt DataReceiver"
        },
        {
            "location": "/tutos/osh-by-example-2/#extract-the-timestamp",
            "text": "Every data sent by the server includes a timestamp, the client has to extract it. In this example, the server \ncould send something like  \"1977-04-22T06:00:00Z,2.464,5.278,30.0\" :  parseTimeStamp: function($super,data){\n    // get record from websocket\n    var record = String.fromCharCode.apply(null, new Uint8Array(data));\n\n    // split the record using  ,  as separator\n    var tokens = record.trim().split( , );\n\n    // return the timeStamp using Data JS Object and getTime (milliseconds)\n    return new Date(tokens[0]).getTime();\n}",
            "title": "Extract the timeStamp"
        },
        {
            "location": "/tutos/osh-by-example-2/#extract-the-data",
            "text": "You need now to extract the  2.464,5.278,30.0  part:  parseData: function($super,data){\n    // get data from WebSocket\n    var record = String.fromCharCode.apply(null, new Uint8Array(data));\n\n    // split String using  ,  as separator\n    var tokens = record.trim().split( , );\n\n    // get lat, lon, alt\n    var lat = parseFloat(tokens[1]);\n    var lon = parseFloat(tokens[2]);\n    var alt = parseFloat(tokens[3]);\n\n    // return JS object\n    return {\n      lat : lat,\n      lon : lon,\n      alt : alt\n    };\n}",
            "title": "Extract the data"
        },
        {
            "location": "/tutos/osh-by-example-2/#instantiate-your-new-datareceiver",
            "text": "You can now instantiate your new class:  var myFakeLatLonAlt = new OSH.DataReceiver.MyFakeLatLonAlt( Fake GPS , {\n    protocol :  ws ,\n    service:  SOS ,\n    endpointUrl: hostname +  /sensorhub/sos ,\n    offeringID:  fake-offering , // the corresponding offering\n    observedProperty:  http://www.opengis.net/def/property/OGC/0/PlatformLocation ,\n    startTime:  2016-08-30T19:00:40Z ,\n    endTime:  2016-08-30T19:22:00Z ,\n    replaySpeed: 1,\n    syncMasterTime: true\n});",
            "title": "Instantiate your new DataReceiver"
        },
        {
            "location": "/tutos/osh-by-example-3/",
            "text": "Use the discovery view\n\n\nWhat is it for?\n\n\nThe discovery view is a service allowing one to automatically discover SOS stream provided by an OSH server.\nIt simplifies the action of reading GetCapabilities, creating/instantiating the DataReceiver as well as the View.\nFor now, the discovery service is able to:\n\n\n\n\n\n\nSelect a service\n\n\n\n\n\n\nSelect an offering\n\n\n\n\n\n\nSelect an observableProperty\n\n\n\n\n\n\nSelect Time (start/end)\n\n\n\n\n\n\nSync master time or not\n\n\n\n\n\n\nAttach to an existing entity\n\n\n\n\n\n\nThe kind of view\n\n\n\n\n\n\n\n\nExtends the discovery service feature\n\n\nThe view allows you to extend the basic functionnality to fit as much as possible to your needs:\n\n\n var discoveryView = new OSH.UI.DiscoveryView(\n,{\n        services: [\nhost1\n,\nhost2\n],\n        css: \ndiscovery-view\n,\n        dataReceiverController:dataProviderController,\n        swapId: \ncenter-container\n,\n        entities: [\nsome entity\n],\n        views: [{\n            name: 'Leaflet 2D Map',\n            viewId: leafletMainView.id,\n            type : OSH.UI.DiscoveryView.Type.MARKER_GPS\n        }, {\n            name: 'Cesium 3D Globe',\n            viewId: cesiumMainMapView.id,\n            type : OSH.UI.DiscoveryView.Type.MARKER_GPS\n        },{\n            name: 'Video dialog(H264)',\n            type : OSH.UI.DiscoveryView.Type.DIALOG_VIDEO_H264\n        },{\n            name: 'Video dialog(MJPEG)',\n            type : OSH.UI.DiscoveryView.Type.DIALOG_VIDEO_MJPEG\n        },{\n            name: 'Chart dialog',\n            type : OSH.UI.DiscoveryView.Type.DIALOG_CHART\n        }\n        ]\n    });\n\n\n\n\nThe \nservices\n property is the endpoint url of the different servers you want to discover the services.\nLike the other views, the discovery view can be styled using the \ncss\n property. You can specify \nan existing \ndataReceiverController\n if you have one, otherwise, the data source will be independently connected.\nOnce the offering and observedProperty discovered, the final data receiver can be attached to an existing entity using\nthe \nentities\n property.\n\n\nThe \nviews\n array provides a way to create automatically a view linked to your data source. For the moment, only a few views are available\nbut you can extend the discovery view to add more.\n\n\nThe \nviewId\n is the div id to attach your view, you can select an existing one (the one from your application, an existing dialog etc.) \nor uses the \nOSH.UI.DiscoveryView.Type.DIALOG_*\n which will popup a new dialog window.\n\n\nSee more types..",
            "title": "Use the discovery view"
        },
        {
            "location": "/tutos/osh-by-example-3/#use-the-discovery-view",
            "text": "",
            "title": "Use the discovery view"
        },
        {
            "location": "/tutos/osh-by-example-3/#what-is-it-for",
            "text": "The discovery view is a service allowing one to automatically discover SOS stream provided by an OSH server.\nIt simplifies the action of reading GetCapabilities, creating/instantiating the DataReceiver as well as the View.\nFor now, the discovery service is able to:    Select a service    Select an offering    Select an observableProperty    Select Time (start/end)    Sync master time or not    Attach to an existing entity    The kind of view",
            "title": "What is it for?"
        },
        {
            "location": "/tutos/osh-by-example-3/#extends-the-discovery-service-feature",
            "text": "The view allows you to extend the basic functionnality to fit as much as possible to your needs:   var discoveryView = new OSH.UI.DiscoveryView( ,{\n        services: [ host1 , host2 ],\n        css:  discovery-view ,\n        dataReceiverController:dataProviderController,\n        swapId:  center-container ,\n        entities: [ some entity ],\n        views: [{\n            name: 'Leaflet 2D Map',\n            viewId: leafletMainView.id,\n            type : OSH.UI.DiscoveryView.Type.MARKER_GPS\n        }, {\n            name: 'Cesium 3D Globe',\n            viewId: cesiumMainMapView.id,\n            type : OSH.UI.DiscoveryView.Type.MARKER_GPS\n        },{\n            name: 'Video dialog(H264)',\n            type : OSH.UI.DiscoveryView.Type.DIALOG_VIDEO_H264\n        },{\n            name: 'Video dialog(MJPEG)',\n            type : OSH.UI.DiscoveryView.Type.DIALOG_VIDEO_MJPEG\n        },{\n            name: 'Chart dialog',\n            type : OSH.UI.DiscoveryView.Type.DIALOG_CHART\n        }\n        ]\n    });  The  services  property is the endpoint url of the different servers you want to discover the services.\nLike the other views, the discovery view can be styled using the  css  property. You can specify \nan existing  dataReceiverController  if you have one, otherwise, the data source will be independently connected.\nOnce the offering and observedProperty discovered, the final data receiver can be attached to an existing entity using\nthe  entities  property.  The  views  array provides a way to create automatically a view linked to your data source. For the moment, only a few views are available\nbut you can extend the discovery view to add more.  The  viewId  is the div id to attach your view, you can select an existing one (the one from your application, an existing dialog etc.) \nor uses the  OSH.UI.DiscoveryView.Type.DIALOG_*  which will popup a new dialog window.  See more types..",
            "title": "Extends the discovery service feature"
        },
        {
            "location": "/license/",
            "text": "License\n\n\nOpenSensorHub is licensed under the Mozilla Public License, version 2.0, whose terms are as follows:\n\n\n\nMozilla Public License, version 2.0\n\n1. Definitions\n\n1.1. \"Contributor\"\n\n     means each individual or legal entity that creates, contributes to the\n     creation of, or owns Covered Software.\n\n1.2. \"Contributor Version\"\n\n     means the combination of the Contributions of others (if any) used by a\n     Contributor and that particular Contributor's Contribution.\n\n1.3. \"Contribution\"\n\n     means Covered Software of a particular Contributor.\n\n1.4. \"Covered Software\"\n\n     means Source Code Form to which the initial Contributor has attached the\n     notice in Exhibit A, the Executable Form of such Source Code Form, and\n     Modifications of such Source Code Form, in each case including portions\n     thereof.\n\n1.5. \"Incompatible With Secondary Licenses\"\n     means\n\n     a. that the initial Contributor has attached the notice described in\n        Exhibit B to the Covered Software; or\n\n     b. that the Covered Software was made available under the terms of\n        version 1.1 or earlier of the License, but not also under the terms of\n        a Secondary License.\n\n1.6. \"Executable Form\"\n\n     means any form of the work other than Source Code Form.\n\n1.7. \"Larger Work\"\n\n     means a work that combines Covered Software with other material, in a\n     separate file or files, that is not Covered Software.\n\n1.8. \"License\"\n\n     means this document.\n\n1.9. \"Licensable\"\n\n     means having the right to grant, to the maximum extent possible, whether\n     at the time of the initial grant or subsequently, any and all of the\n     rights conveyed by this License.\n\n1.10. \"Modifications\"\n\n     means any of the following:\n\n     a. any file in Source Code Form that results from an addition to,\n        deletion from, or modification of the contents of Covered Software; or\n\n     b. any new file in Source Code Form that contains any Covered Software.\n\n1.11. \"Patent Claims\" of a Contributor\n\n      means any patent claim(s), including without limitation, method,\n      process, and apparatus claims, in any patent Licensable by such\n      Contributor that would be infringed, but for the grant of the License,\n      by the making, using, selling, offering for sale, having made, import,\n      or transfer of either its Contributions or its Contributor Version.\n\n1.12. \"Secondary License\"\n\n      means either the GNU General Public License, Version 2.0, the GNU Lesser\n      General Public License, Version 2.1, the GNU Affero General Public\n      License, Version 3.0, or any later versions of those licenses.\n\n1.13. \"Source Code Form\"\n\n      means the form of the work preferred for making modifications.\n\n1.14. \"You\" (or \"Your\")\n\n      means an individual or a legal entity exercising rights under this\n      License. For legal entities, \"You\" includes any entity that controls, is\n      controlled by, or is under common control with You. For purposes of this\n      definition, \"control\" means (a) the power, direct or indirect, to cause\n      the direction or management of such entity, whether by contract or\n      otherwise, or (b) ownership of more than fifty percent (50%) of the\n      outstanding shares or beneficial ownership of such entity.\n\n\n2. License Grants and Conditions\n\n2.1. Grants\n\n     Each Contributor hereby grants You a world-wide, royalty-free,\n     non-exclusive license:\n\n     a. under intellectual property rights (other than patent or trademark)\n        Licensable by such Contributor to use, reproduce, make available,\n        modify, display, perform, distribute, and otherwise exploit its\n        Contributions, either on an unmodified basis, with Modifications, or\n        as part of a Larger Work; and\n\n     b. under Patent Claims of such Contributor to make, use, sell, offer for\n        sale, have made, import, and otherwise transfer either its\n        Contributions or its Contributor Version.\n\n2.2. Effective Date\n\n     The licenses granted in Section 2.1 with respect to any Contribution\n     become effective for each Contribution on the date the Contributor first\n     distributes such Contribution.\n\n2.3. Limitations on Grant Scope\n\n     The licenses granted in this Section 2 are the only rights granted under\n     this License. No additional rights or licenses will be implied from the\n     distribution or licensing of Covered Software under this License.\n     Notwithstanding Section 2.1(b) above, no patent license is granted by a\n     Contributor:\n\n     a. for any code that a Contributor has removed from Covered Software; or\n\n     b. for infringements caused by: (i) Your and any other third party's\n        modifications of Covered Software, or (ii) the combination of its\n        Contributions with other software (except as part of its Contributor\n        Version); or\n\n     c. under Patent Claims infringed by Covered Software in the absence of\n        its Contributions.\n\n     This License does not grant any rights in the trademarks, service marks,\n     or logos of any Contributor (except as may be necessary to comply with\n     the notice requirements in Section 3.4).\n\n2.4. Subsequent Licenses\n\n     No Contributor makes additional grants as a result of Your choice to\n     distribute the Covered Software under a subsequent version of this\n     License (see Section 10.2) or under the terms of a Secondary License (if\n     permitted under the terms of Section 3.3).\n\n2.5. Representation\n\n     Each Contributor represents that the Contributor believes its\n     Contributions are its original creation(s) or it has sufficient rights to\n     grant the rights to its Contributions conveyed by this License.\n\n2.6. Fair Use\n\n     This License is not intended to limit any rights You have under\n     applicable copyright doctrines of fair use, fair dealing, or other\n     equivalents.\n\n2.7. Conditions\n\n     Sections 3.1, 3.2, 3.3, and 3.4 are conditions of the licenses granted in\n     Section 2.1.\n\n\n3. Responsibilities\n\n3.1. Distribution of Source Form\n\n     All distribution of Covered Software in Source Code Form, including any\n     Modifications that You create or to which You contribute, must be under\n     the terms of this License. You must inform recipients that the Source\n     Code Form of the Covered Software is governed by the terms of this\n     License, and how they can obtain a copy of this License. You may not\n     attempt to alter or restrict the recipients' rights in the Source Code\n     Form.\n\n3.2. Distribution of Executable Form\n\n     If You distribute Covered Software in Executable Form then:\n\n     a. such Covered Software must also be made available in Source Code Form,\n        as described in Section 3.1, and You must inform recipients of the\n        Executable Form how they can obtain a copy of such Source Code Form by\n        reasonable means in a timely manner, at a charge no more than the cost\n        of distribution to the recipient; and\n\n     b. You may distribute such Executable Form under the terms of this\n        License, or sublicense it under different terms, provided that the\n        license for the Executable Form does not attempt to limit or alter the\n        recipients' rights in the Source Code Form under this License.\n\n3.3. Distribution of a Larger Work\n\n     You may create and distribute a Larger Work under terms of Your choice,\n     provided that You also comply with the requirements of this License for\n     the Covered Software. If the Larger Work is a combination of Covered\n     Software with a work governed by one or more Secondary Licenses, and the\n     Covered Software is not Incompatible With Secondary Licenses, this\n     License permits You to additionally distribute such Covered Software\n     under the terms of such Secondary License(s), so that the recipient of\n     the Larger Work may, at their option, further distribute the Covered\n     Software under the terms of either this License or such Secondary\n     License(s).\n\n3.4. Notices\n\n     You may not remove or alter the substance of any license notices\n     (including copyright notices, patent notices, disclaimers of warranty, or\n     limitations of liability) contained within the Source Code Form of the\n     Covered Software, except that You may alter any license notices to the\n     extent required to remedy known factual inaccuracies.\n\n3.5. Application of Additional Terms\n\n     You may choose to offer, and to charge a fee for, warranty, support,\n     indemnity or liability obligations to one or more recipients of Covered\n     Software. However, You may do so only on Your own behalf, and not on\n     behalf of any Contributor. You must make it absolutely clear that any\n     such warranty, support, indemnity, or liability obligation is offered by\n     You alone, and You hereby agree to indemnify every Contributor for any\n     liability incurred by such Contributor as a result of warranty, support,\n     indemnity or liability terms You offer. You may include additional\n     disclaimers of warranty and limitations of liability specific to any\n     jurisdiction.\n\n4. Inability to Comply Due to Statute or Regulation\n\n   If it is impossible for You to comply with any of the terms of this License\n   with respect to some or all of the Covered Software due to statute,\n   judicial order, or regulation then You must: (a) comply with the terms of\n   this License to the maximum extent possible; and (b) describe the\n   limitations and the code they affect. Such description must be placed in a\n   text file included with all distributions of the Covered Software under\n   this License. Except to the extent prohibited by statute or regulation,\n   such description must be sufficiently detailed for a recipient of ordinary\n   skill to be able to understand it.\n\n5. Termination\n\n5.1. The rights granted under this License will terminate automatically if You\n     fail to comply with any of its terms. However, if You become compliant,\n     then the rights granted under this License from a particular Contributor\n     are reinstated (a) provisionally, unless and until such Contributor\n     explicitly and finally terminates Your grants, and (b) on an ongoing\n     basis, if such Contributor fails to notify You of the non-compliance by\n     some reasonable means prior to 60 days after You have come back into\n     compliance. Moreover, Your grants from a particular Contributor are\n     reinstated on an ongoing basis if such Contributor notifies You of the\n     non-compliance by some reasonable means, this is the first time You have\n     received notice of non-compliance with this License from such\n     Contributor, and You become compliant prior to 30 days after Your receipt\n     of the notice.\n\n5.2. If You initiate litigation against any entity by asserting a patent\n     infringement claim (excluding declaratory judgment actions,\n     counter-claims, and cross-claims) alleging that a Contributor Version\n     directly or indirectly infringes any patent, then the rights granted to\n     You by any and all Contributors for the Covered Software under Section\n     2.1 of this License shall terminate.\n\n5.3. In the event of termination under Sections 5.1 or 5.2 above, all end user\n     license agreements (excluding distributors and resellers) which have been\n     validly granted by You or Your distributors under this License prior to\n     termination shall survive termination.\n\n6. Disclaimer of Warranty\n\n   Covered Software is provided under this License on an \"as is\" basis,\n   without warranty of any kind, either expressed, implied, or statutory,\n   including, without limitation, warranties that the Covered Software is free\n   of defects, merchantable, fit for a particular purpose or non-infringing.\n   The entire risk as to the quality and performance of the Covered Software\n   is with You. Should any Covered Software prove defective in any respect,\n   You (not any Contributor) assume the cost of any necessary servicing,\n   repair, or correction. This disclaimer of warranty constitutes an essential\n   part of this License. No use of  any Covered Software is authorized under\n   this License except under this disclaimer.\n\n7. Limitation of Liability\n\n   Under no circumstances and under no legal theory, whether tort (including\n   negligence), contract, or otherwise, shall any Contributor, or anyone who\n   distributes Covered Software as permitted above, be liable to You for any\n   direct, indirect, special, incidental, or consequential damages of any\n   character including, without limitation, damages for lost profits, loss of\n   goodwill, work stoppage, computer failure or malfunction, or any and all\n   other commercial damages or losses, even if such party shall have been\n   informed of the possibility of such damages. This limitation of liability\n   shall not apply to liability for death or personal injury resulting from\n   such party's negligence to the extent applicable law prohibits such\n   limitation. Some jurisdictions do not allow the exclusion or limitation of\n   incidental or consequential damages, so this exclusion and limitation may\n   not apply to You.\n\n8. Litigation\n\n   Any litigation relating to this License may be brought only in the courts\n   of a jurisdiction where the defendant maintains its principal place of\n   business and such litigation shall be governed by laws of that\n   jurisdiction, without reference to its conflict-of-law provisions. Nothing\n   in this Section shall prevent a party's ability to bring cross-claims or\n   counter-claims.\n\n9. Miscellaneous\n\n   This License represents the complete agreement concerning the subject\n   matter hereof. If any provision of this License is held to be\n   unenforceable, such provision shall be reformed only to the extent\n   necessary to make it enforceable. Any law or regulation which provides that\n   the language of a contract shall be construed against the drafter shall not\n   be used to construe this License against a Contributor.\n\n\n10. Versions of the License\n\n10.1. New Versions\n\n      Mozilla Foundation is the license steward. Except as provided in Section\n      10.3, no one other than the license steward has the right to modify or\n      publish new versions of this License. Each version will be given a\n      distinguishing version number.\n\n10.2. Effect of New Versions\n\n      You may distribute the Covered Software under the terms of the version\n      of the License under which You originally received the Covered Software,\n      or under the terms of any subsequent version published by the license\n      steward.\n\n10.3. Modified Versions\n\n      If you create software not governed by this License, and you want to\n      create a new license for such software, you may create and use a\n      modified version of this License if you rename the license and remove\n      any references to the name of the license steward (except to note that\n      such modified license differs from this License).\n\n10.4. Distributing Source Code Form that is Incompatible With Secondary\n      Licenses If You choose to distribute Source Code Form that is\n      Incompatible With Secondary Licenses under the terms of this version of\n      the License, the notice described in Exhibit B of this License must be\n      attached.\n\nExhibit A - Source Code Form License Notice\n\n      This Source Code Form is subject to the\n      terms of the Mozilla Public License, v.\n      2.0. If a copy of the MPL was not\n      distributed with this file, You can\n      obtain one at\n      http://mozilla.org/MPL/2.0/.\n\nIf it is not possible or desirable to put the notice in a particular file,\nthen You may include the notice in a location (such as a LICENSE file in a\nrelevant directory) where a recipient would be likely to look for such a\nnotice.\n\nYou may add additional accurate notices of copyright ownership.\n\nExhibit B - \"Incompatible With Secondary Licenses\" Notice\n\n      This Source Code Form is \"Incompatible\n      With Secondary Licenses\", as defined by\n      the Mozilla Public License, v. 2.0.",
            "title": "License"
        },
        {
            "location": "/license/#license",
            "text": "OpenSensorHub is licensed under the Mozilla Public License, version 2.0, whose terms are as follows:  \nMozilla Public License, version 2.0\n\n1. Definitions\n\n1.1. \"Contributor\"\n\n     means each individual or legal entity that creates, contributes to the\n     creation of, or owns Covered Software.\n\n1.2. \"Contributor Version\"\n\n     means the combination of the Contributions of others (if any) used by a\n     Contributor and that particular Contributor's Contribution.\n\n1.3. \"Contribution\"\n\n     means Covered Software of a particular Contributor.\n\n1.4. \"Covered Software\"\n\n     means Source Code Form to which the initial Contributor has attached the\n     notice in Exhibit A, the Executable Form of such Source Code Form, and\n     Modifications of such Source Code Form, in each case including portions\n     thereof.\n\n1.5. \"Incompatible With Secondary Licenses\"\n     means\n\n     a. that the initial Contributor has attached the notice described in\n        Exhibit B to the Covered Software; or\n\n     b. that the Covered Software was made available under the terms of\n        version 1.1 or earlier of the License, but not also under the terms of\n        a Secondary License.\n\n1.6. \"Executable Form\"\n\n     means any form of the work other than Source Code Form.\n\n1.7. \"Larger Work\"\n\n     means a work that combines Covered Software with other material, in a\n     separate file or files, that is not Covered Software.\n\n1.8. \"License\"\n\n     means this document.\n\n1.9. \"Licensable\"\n\n     means having the right to grant, to the maximum extent possible, whether\n     at the time of the initial grant or subsequently, any and all of the\n     rights conveyed by this License.\n\n1.10. \"Modifications\"\n\n     means any of the following:\n\n     a. any file in Source Code Form that results from an addition to,\n        deletion from, or modification of the contents of Covered Software; or\n\n     b. any new file in Source Code Form that contains any Covered Software.\n\n1.11. \"Patent Claims\" of a Contributor\n\n      means any patent claim(s), including without limitation, method,\n      process, and apparatus claims, in any patent Licensable by such\n      Contributor that would be infringed, but for the grant of the License,\n      by the making, using, selling, offering for sale, having made, import,\n      or transfer of either its Contributions or its Contributor Version.\n\n1.12. \"Secondary License\"\n\n      means either the GNU General Public License, Version 2.0, the GNU Lesser\n      General Public License, Version 2.1, the GNU Affero General Public\n      License, Version 3.0, or any later versions of those licenses.\n\n1.13. \"Source Code Form\"\n\n      means the form of the work preferred for making modifications.\n\n1.14. \"You\" (or \"Your\")\n\n      means an individual or a legal entity exercising rights under this\n      License. For legal entities, \"You\" includes any entity that controls, is\n      controlled by, or is under common control with You. For purposes of this\n      definition, \"control\" means (a) the power, direct or indirect, to cause\n      the direction or management of such entity, whether by contract or\n      otherwise, or (b) ownership of more than fifty percent (50%) of the\n      outstanding shares or beneficial ownership of such entity.\n\n\n2. License Grants and Conditions\n\n2.1. Grants\n\n     Each Contributor hereby grants You a world-wide, royalty-free,\n     non-exclusive license:\n\n     a. under intellectual property rights (other than patent or trademark)\n        Licensable by such Contributor to use, reproduce, make available,\n        modify, display, perform, distribute, and otherwise exploit its\n        Contributions, either on an unmodified basis, with Modifications, or\n        as part of a Larger Work; and\n\n     b. under Patent Claims of such Contributor to make, use, sell, offer for\n        sale, have made, import, and otherwise transfer either its\n        Contributions or its Contributor Version.\n\n2.2. Effective Date\n\n     The licenses granted in Section 2.1 with respect to any Contribution\n     become effective for each Contribution on the date the Contributor first\n     distributes such Contribution.\n\n2.3. Limitations on Grant Scope\n\n     The licenses granted in this Section 2 are the only rights granted under\n     this License. No additional rights or licenses will be implied from the\n     distribution or licensing of Covered Software under this License.\n     Notwithstanding Section 2.1(b) above, no patent license is granted by a\n     Contributor:\n\n     a. for any code that a Contributor has removed from Covered Software; or\n\n     b. for infringements caused by: (i) Your and any other third party's\n        modifications of Covered Software, or (ii) the combination of its\n        Contributions with other software (except as part of its Contributor\n        Version); or\n\n     c. under Patent Claims infringed by Covered Software in the absence of\n        its Contributions.\n\n     This License does not grant any rights in the trademarks, service marks,\n     or logos of any Contributor (except as may be necessary to comply with\n     the notice requirements in Section 3.4).\n\n2.4. Subsequent Licenses\n\n     No Contributor makes additional grants as a result of Your choice to\n     distribute the Covered Software under a subsequent version of this\n     License (see Section 10.2) or under the terms of a Secondary License (if\n     permitted under the terms of Section 3.3).\n\n2.5. Representation\n\n     Each Contributor represents that the Contributor believes its\n     Contributions are its original creation(s) or it has sufficient rights to\n     grant the rights to its Contributions conveyed by this License.\n\n2.6. Fair Use\n\n     This License is not intended to limit any rights You have under\n     applicable copyright doctrines of fair use, fair dealing, or other\n     equivalents.\n\n2.7. Conditions\n\n     Sections 3.1, 3.2, 3.3, and 3.4 are conditions of the licenses granted in\n     Section 2.1.\n\n\n3. Responsibilities\n\n3.1. Distribution of Source Form\n\n     All distribution of Covered Software in Source Code Form, including any\n     Modifications that You create or to which You contribute, must be under\n     the terms of this License. You must inform recipients that the Source\n     Code Form of the Covered Software is governed by the terms of this\n     License, and how they can obtain a copy of this License. You may not\n     attempt to alter or restrict the recipients' rights in the Source Code\n     Form.\n\n3.2. Distribution of Executable Form\n\n     If You distribute Covered Software in Executable Form then:\n\n     a. such Covered Software must also be made available in Source Code Form,\n        as described in Section 3.1, and You must inform recipients of the\n        Executable Form how they can obtain a copy of such Source Code Form by\n        reasonable means in a timely manner, at a charge no more than the cost\n        of distribution to the recipient; and\n\n     b. You may distribute such Executable Form under the terms of this\n        License, or sublicense it under different terms, provided that the\n        license for the Executable Form does not attempt to limit or alter the\n        recipients' rights in the Source Code Form under this License.\n\n3.3. Distribution of a Larger Work\n\n     You may create and distribute a Larger Work under terms of Your choice,\n     provided that You also comply with the requirements of this License for\n     the Covered Software. If the Larger Work is a combination of Covered\n     Software with a work governed by one or more Secondary Licenses, and the\n     Covered Software is not Incompatible With Secondary Licenses, this\n     License permits You to additionally distribute such Covered Software\n     under the terms of such Secondary License(s), so that the recipient of\n     the Larger Work may, at their option, further distribute the Covered\n     Software under the terms of either this License or such Secondary\n     License(s).\n\n3.4. Notices\n\n     You may not remove or alter the substance of any license notices\n     (including copyright notices, patent notices, disclaimers of warranty, or\n     limitations of liability) contained within the Source Code Form of the\n     Covered Software, except that You may alter any license notices to the\n     extent required to remedy known factual inaccuracies.\n\n3.5. Application of Additional Terms\n\n     You may choose to offer, and to charge a fee for, warranty, support,\n     indemnity or liability obligations to one or more recipients of Covered\n     Software. However, You may do so only on Your own behalf, and not on\n     behalf of any Contributor. You must make it absolutely clear that any\n     such warranty, support, indemnity, or liability obligation is offered by\n     You alone, and You hereby agree to indemnify every Contributor for any\n     liability incurred by such Contributor as a result of warranty, support,\n     indemnity or liability terms You offer. You may include additional\n     disclaimers of warranty and limitations of liability specific to any\n     jurisdiction.\n\n4. Inability to Comply Due to Statute or Regulation\n\n   If it is impossible for You to comply with any of the terms of this License\n   with respect to some or all of the Covered Software due to statute,\n   judicial order, or regulation then You must: (a) comply with the terms of\n   this License to the maximum extent possible; and (b) describe the\n   limitations and the code they affect. Such description must be placed in a\n   text file included with all distributions of the Covered Software under\n   this License. Except to the extent prohibited by statute or regulation,\n   such description must be sufficiently detailed for a recipient of ordinary\n   skill to be able to understand it.\n\n5. Termination\n\n5.1. The rights granted under this License will terminate automatically if You\n     fail to comply with any of its terms. However, if You become compliant,\n     then the rights granted under this License from a particular Contributor\n     are reinstated (a) provisionally, unless and until such Contributor\n     explicitly and finally terminates Your grants, and (b) on an ongoing\n     basis, if such Contributor fails to notify You of the non-compliance by\n     some reasonable means prior to 60 days after You have come back into\n     compliance. Moreover, Your grants from a particular Contributor are\n     reinstated on an ongoing basis if such Contributor notifies You of the\n     non-compliance by some reasonable means, this is the first time You have\n     received notice of non-compliance with this License from such\n     Contributor, and You become compliant prior to 30 days after Your receipt\n     of the notice.\n\n5.2. If You initiate litigation against any entity by asserting a patent\n     infringement claim (excluding declaratory judgment actions,\n     counter-claims, and cross-claims) alleging that a Contributor Version\n     directly or indirectly infringes any patent, then the rights granted to\n     You by any and all Contributors for the Covered Software under Section\n     2.1 of this License shall terminate.\n\n5.3. In the event of termination under Sections 5.1 or 5.2 above, all end user\n     license agreements (excluding distributors and resellers) which have been\n     validly granted by You or Your distributors under this License prior to\n     termination shall survive termination.\n\n6. Disclaimer of Warranty\n\n   Covered Software is provided under this License on an \"as is\" basis,\n   without warranty of any kind, either expressed, implied, or statutory,\n   including, without limitation, warranties that the Covered Software is free\n   of defects, merchantable, fit for a particular purpose or non-infringing.\n   The entire risk as to the quality and performance of the Covered Software\n   is with You. Should any Covered Software prove defective in any respect,\n   You (not any Contributor) assume the cost of any necessary servicing,\n   repair, or correction. This disclaimer of warranty constitutes an essential\n   part of this License. No use of  any Covered Software is authorized under\n   this License except under this disclaimer.\n\n7. Limitation of Liability\n\n   Under no circumstances and under no legal theory, whether tort (including\n   negligence), contract, or otherwise, shall any Contributor, or anyone who\n   distributes Covered Software as permitted above, be liable to You for any\n   direct, indirect, special, incidental, or consequential damages of any\n   character including, without limitation, damages for lost profits, loss of\n   goodwill, work stoppage, computer failure or malfunction, or any and all\n   other commercial damages or losses, even if such party shall have been\n   informed of the possibility of such damages. This limitation of liability\n   shall not apply to liability for death or personal injury resulting from\n   such party's negligence to the extent applicable law prohibits such\n   limitation. Some jurisdictions do not allow the exclusion or limitation of\n   incidental or consequential damages, so this exclusion and limitation may\n   not apply to You.\n\n8. Litigation\n\n   Any litigation relating to this License may be brought only in the courts\n   of a jurisdiction where the defendant maintains its principal place of\n   business and such litigation shall be governed by laws of that\n   jurisdiction, without reference to its conflict-of-law provisions. Nothing\n   in this Section shall prevent a party's ability to bring cross-claims or\n   counter-claims.\n\n9. Miscellaneous\n\n   This License represents the complete agreement concerning the subject\n   matter hereof. If any provision of this License is held to be\n   unenforceable, such provision shall be reformed only to the extent\n   necessary to make it enforceable. Any law or regulation which provides that\n   the language of a contract shall be construed against the drafter shall not\n   be used to construe this License against a Contributor.\n\n\n10. Versions of the License\n\n10.1. New Versions\n\n      Mozilla Foundation is the license steward. Except as provided in Section\n      10.3, no one other than the license steward has the right to modify or\n      publish new versions of this License. Each version will be given a\n      distinguishing version number.\n\n10.2. Effect of New Versions\n\n      You may distribute the Covered Software under the terms of the version\n      of the License under which You originally received the Covered Software,\n      or under the terms of any subsequent version published by the license\n      steward.\n\n10.3. Modified Versions\n\n      If you create software not governed by this License, and you want to\n      create a new license for such software, you may create and use a\n      modified version of this License if you rename the license and remove\n      any references to the name of the license steward (except to note that\n      such modified license differs from this License).\n\n10.4. Distributing Source Code Form that is Incompatible With Secondary\n      Licenses If You choose to distribute Source Code Form that is\n      Incompatible With Secondary Licenses under the terms of this version of\n      the License, the notice described in Exhibit B of this License must be\n      attached.\n\nExhibit A - Source Code Form License Notice\n\n      This Source Code Form is subject to the\n      terms of the Mozilla Public License, v.\n      2.0. If a copy of the MPL was not\n      distributed with this file, You can\n      obtain one at\n      http://mozilla.org/MPL/2.0/.\n\nIf it is not possible or desirable to put the notice in a particular file,\nthen You may include the notice in a location (such as a LICENSE file in a\nrelevant directory) where a recipient would be likely to look for such a\nnotice.\n\nYou may add additional accurate notices of copyright ownership.\n\nExhibit B - \"Incompatible With Secondary Licenses\" Notice\n\n      This Source Code Form is \"Incompatible\n      With Secondary Licenses\", as defined by\n      the Mozilla Public License, v. 2.0.",
            "title": "License"
        }
    ]
}